{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.threading.set_intra_op_parallelism_threads(6)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "import gym\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_url = [\n",
    "#     \"https://www.bbci.de/competition/download/competition_iv/BCICIV_2a_gdf.zip\"\n",
    "# ]\n",
    "\n",
    "# for i in download_url:\n",
    "#     os.system(\"wget --no-check-certificate -P /mnt/Data/Data/EEG_Converted \"+i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import time\n",
    "\n",
    "dataset = []\n",
    "labels = []\n",
    "multigrasp_dataset = []\n",
    "reaching_dataset = []\n",
    "twist_dataset = []\n",
    "for filename in os.listdir('/mnt/Data/Data/EEG_Converted'):\n",
    "    if 'MI' in filename:\n",
    "        filepath = os.path.join('/mnt/Data/Data/EEG_Converted', filename)\n",
    "        data = scipy.io.loadmat(filepath)\n",
    "        data.pop('__header__')\n",
    "        data.pop('__version__')\n",
    "        data.pop('__globals__')\n",
    "        data.pop('mrk')\n",
    "        data.pop('mnt')\n",
    "        data.pop('nfo')\n",
    "        data.pop('dat')\n",
    "        \n",
    "        data_arr = np.array(data['ch15'])\n",
    "        for ch in range(16, 19):\n",
    "            data_arr = np.concatenate((data_arr, data['ch'+str(ch)]), axis=1)\n",
    "        for ch in range(43, 46):\n",
    "            data_arr = np.concatenate((data_arr, data['ch'+str(ch)]), axis=1)\n",
    "        data_arr = data_arr.T\n",
    "        if 'multigrasp_MI' in filename:\n",
    "            multigrasp_dataset.append(data_arr)\n",
    "        if 'reaching_MI' in filename:\n",
    "            reaching_dataset.append(data_arr)\n",
    "        if 'twist_MI' in filename:\n",
    "            twist_dataset.append(data_arr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dataset):\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = np.resize(dataset[i],(7,2**23))\n",
    "        d = dataset[i].astype(float)\n",
    "        dataset[i] = mne.filter.filter_data(d, l_freq=0.1, h_freq=50,sfreq=2500)\n",
    "        print(d.shape)\n",
    "        \n",
    "    dataset = np.array(dataset)\n",
    "    print(dataset.shape)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Info | 8 non-empty values\n",
      " bads: []\n",
      " ch_names: C5, C3, C1, Cz, C2, C4, C6\n",
      " chs: 7 EEG\n",
      " custom_ref_applied: False\n",
      " dig: 10 items (3 Cardinal, 7 EEG)\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 1250.0 Hz\n",
      " meas_date: unspecified\n",
      " nchan: 7\n",
      " projs: []\n",
      " sfreq: 2500.0 Hz\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#chan_names = ['Fp1','AF7','AF3','AFz','F7','F5','F3','F1','Fz','FT7','FC5','FC3','FC1','T7','C5','C3','C1','Cz','TP7','CP5','CP3','CP1','CPz','P7','P5','P3','P1','Pz','PO7','PO3','POz','Fp2','AF4','AF8','F2','F4','F6','F8','FC2','FC4','FC6','FT8','C2','C4','C6','T8','CP2','CP4','CP6','TP8','P2','P4','P6','P8','PO4','PO8','O1','Oz','O2','Iz']\n",
    "chan_names = ['C5','C3','C1','Cz','C2','C4','C6']\n",
    "info = mne.create_info(ch_names=chan_names, ch_types=['eeg']*7, sfreq=2500)\n",
    "info.set_montage('standard_1020')\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "multigrasp_epochs = mne.EpochsArray(data=read_data(multigrasp_dataset), info=info)\n",
    "reaching_epochs = mne.EpochsArray(data=read_data(reaching_dataset), info=info)\n",
    "twist_epochs = mne.EpochsArray(data=read_data(twist_dataset), info=info)\n",
    "multigrasp_epochs1 = mne.EpochsArray(data=(multigrasp_dataset), info=info)\n",
    "reaching_epochs1 = mne.EpochsArray(data=(reaching_dataset), info=info)\n",
    "twist_epochs1 = mne.EpochsArray(data=(twist_dataset), info=info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "36\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "from mne.time_frequency import tfr_morlet\n",
    "%matplotlib inline\n",
    "print(len(multigrasp_dataset))\n",
    "print(len(reaching_dataset))\n",
    "print(len(twist_dataset))\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(10):\n",
    "#     print(\"________________________________ \",i+1)\n",
    "#     d = multigrasp_epochs.get_data()[i]\n",
    "#     theta = mne.filter.filter_data(d, sfreq=2500, l_freq=4, h_freq=8,verbose=False)\n",
    "#     alpha = mne.filter.filter_data(d, sfreq=2500, l_freq=8, h_freq=12,verbose=False)\n",
    "#     beta = mne.filter.filter_data(d, sfreq=2500, l_freq=12, h_freq=30,verbose=False)\n",
    "#     delta = mne.filter.filter_data(d, sfreq=2500, l_freq=0.5, h_freq=4,verbose=False)\n",
    "#     t_evoked = mne.EvokedArray(theta, info, tmin=0)\n",
    "#     a_evoked = mne.EvokedArray(alpha, info, tmin=0)\n",
    "#     b_evoked = mne.EvokedArray(beta, info, tmin=0)\n",
    "#     d_evoked = mne.EvokedArray(delta, info, tmin=0)\n",
    "#     print(\"theta\")\n",
    "#     t_evoked.plot()\n",
    "#     print(\"alpha\")\n",
    "#     a_evoked.plot()\n",
    "#     print(\"beta\")\n",
    "#     b_evoked.plot()\n",
    "#     print(\"delta\")\n",
    "#     d_evoked.plot()\n",
    "    \n",
    "#     print(\"________________________________ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'multigrasp_epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/eeshan/Music/KernelModuleDefs/SystemIntegrityProtocols/5eee7de7454beed9d83660fb3a4535c1/3202b0f40c9b6d03df8679cc2d85fea0/85df3becdfcb4d7e35c74befeee54aa5/33507a4383e3645034645fb210bfebbe/ffc1b50d6da82d6fbbfaad7d8e06c271/a/NeuroAssist (1) copy.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://tunnel%2Btbam-workstation/home/eeshan/Music/KernelModuleDefs/SystemIntegrityProtocols/5eee7de7454beed9d83660fb3a4535c1/3202b0f40c9b6d03df8679cc2d85fea0/85df3becdfcb4d7e35c74befeee54aa5/33507a4383e3645034645fb210bfebbe/ffc1b50d6da82d6fbbfaad7d8e06c271/a/NeuroAssist%20%281%29%20copy.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Btbam-workstation/home/eeshan/Music/KernelModuleDefs/SystemIntegrityProtocols/5eee7de7454beed9d83660fb3a4535c1/3202b0f40c9b6d03df8679cc2d85fea0/85df3becdfcb4d7e35c74befeee54aa5/33507a4383e3645034645fb210bfebbe/ffc1b50d6da82d6fbbfaad7d8e06c271/a/NeuroAssist%20%281%29%20copy.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m data_list \u001b[39m=\u001b[39m []\n\u001b[0;32m---> <a href='vscode-notebook-cell://tunnel%2Btbam-workstation/home/eeshan/Music/KernelModuleDefs/SystemIntegrityProtocols/5eee7de7454beed9d83660fb3a4535c1/3202b0f40c9b6d03df8679cc2d85fea0/85df3becdfcb4d7e35c74befeee54aa5/33507a4383e3645034645fb210bfebbe/ffc1b50d6da82d6fbbfaad7d8e06c271/a/NeuroAssist%20%281%29%20copy.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m data_list\u001b[39m.\u001b[39mappend(multigrasp_epochs\u001b[39m.\u001b[39mget_data())\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Btbam-workstation/home/eeshan/Music/KernelModuleDefs/SystemIntegrityProtocols/5eee7de7454beed9d83660fb3a4535c1/3202b0f40c9b6d03df8679cc2d85fea0/85df3becdfcb4d7e35c74befeee54aa5/33507a4383e3645034645fb210bfebbe/ffc1b50d6da82d6fbbfaad7d8e06c271/a/NeuroAssist%20%281%29%20copy.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m data_list\u001b[39m.\u001b[39mappend(reaching_epochs\u001b[39m.\u001b[39mget_data())\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Btbam-workstation/home/eeshan/Music/KernelModuleDefs/SystemIntegrityProtocols/5eee7de7454beed9d83660fb3a4535c1/3202b0f40c9b6d03df8679cc2d85fea0/85df3becdfcb4d7e35c74befeee54aa5/33507a4383e3645034645fb210bfebbe/ffc1b50d6da82d6fbbfaad7d8e06c271/a/NeuroAssist%20%281%29%20copy.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m data_list\u001b[39m.\u001b[39mappend(twist_epochs\u001b[39m.\u001b[39mget_data())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'multigrasp_epochs' is not defined"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "import gym\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "data_list = []\n",
    "data_list.append(multigrasp_epochs.get_data())\n",
    "data_list.append(reaching_epochs.get_data())\n",
    "data_list.append(twist_epochs.get_data())\n",
    "multigrasp_labels = [0 for i in range(36)] #[0 for i in range(multigrasp_epochs.get_data().shape[0])]\n",
    "print(multigrasp_labels)\n",
    "\n",
    "reaching_labels = [1 for i in range(36)]\n",
    "print(reaching_labels)\n",
    "\n",
    "twist_labels = [2 for i in range(36)]\n",
    "print(twist_labels)\n",
    "\n",
    "label_list = multigrasp_labels + reaching_labels + twist_labels\n",
    "\n",
    "\n",
    "data_array = np.vstack(data_list)\n",
    "label_array = np.hstack(label_list)\n",
    "\n",
    "print(label_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p (129,)\n",
      "p (129,)\n",
      "p (129,)\n",
      "p (129,)\n",
      "p (129,)\n",
      "p (129,)\n",
      "p (129,)\n",
      "p (129,)\n",
      "p (129,)\n",
      "p (129,)\n",
      "p (129,)\n",
      "p (129,)\n",
      "p (129,)\n",
      "p (129,)\n",
      "p (129,)\n",
      "p (129,)\n",
      "p (129,)\n",
      "p (129,)\n",
      "p (129,)\n",
      "p (129,)\n",
      "p (129,)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/eeshan/Music/KernelModuleDefs/SystemIntegrityProtocols/5eee7de7454beed9d83660fb3a4535c1/3202b0f40c9b6d03df8679cc2d85fea0/85df3becdfcb4d7e35c74befeee54aa5/33507a4383e3645034645fb210bfebbe/ffc1b50d6da82d6fbbfaad7d8e06c271/a/NeuroAssist (1) copy.ipynb Cell 11\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Btbam-workstation/home/eeshan/Music/KernelModuleDefs/SystemIntegrityProtocols/5eee7de7454beed9d83660fb3a4535c1/3202b0f40c9b6d03df8679cc2d85fea0/85df3becdfcb4d7e35c74befeee54aa5/33507a4383e3645034645fb210bfebbe/ffc1b50d6da82d6fbbfaad7d8e06c271/a/NeuroAssist%20%281%29%20copy.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m         features\u001b[39m.\u001b[39mappend(res)\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Btbam-workstation/home/eeshan/Music/KernelModuleDefs/SystemIntegrityProtocols/5eee7de7454beed9d83660fb3a4535c1/3202b0f40c9b6d03df8679cc2d85fea0/85df3becdfcb4d7e35c74befeee54aa5/33507a4383e3645034645fb210bfebbe/ffc1b50d6da82d6fbbfaad7d8e06c271/a/NeuroAssist%20%281%29%20copy.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m features\n\u001b[0;32m---> <a href='vscode-notebook-cell://tunnel%2Btbam-workstation/home/eeshan/Music/KernelModuleDefs/SystemIntegrityProtocols/5eee7de7454beed9d83660fb3a4535c1/3202b0f40c9b6d03df8679cc2d85fea0/85df3becdfcb4d7e35c74befeee54aa5/33507a4383e3645034645fb210bfebbe/ffc1b50d6da82d6fbbfaad7d8e06c271/a/NeuroAssist%20%281%29%20copy.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=67'>68</a>\u001b[0m f \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(featuresarray_load())\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Btbam-workstation/home/eeshan/Music/KernelModuleDefs/SystemIntegrityProtocols/5eee7de7454beed9d83660fb3a4535c1/3202b0f40c9b6d03df8679cc2d85fea0/85df3becdfcb4d7e35c74befeee54aa5/33507a4383e3645034645fb210bfebbe/ffc1b50d6da82d6fbbfaad7d8e06c271/a/NeuroAssist%20%281%29%20copy.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=68'>69</a>\u001b[0m np\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mfeatures_array3.npy\u001b[39m\u001b[39m\"\u001b[39m,allow_pickle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,arr\u001b[39m=\u001b[39mf)\n",
      "\u001b[1;32m/home/eeshan/Music/KernelModuleDefs/SystemIntegrityProtocols/5eee7de7454beed9d83660fb3a4535c1/3202b0f40c9b6d03df8679cc2d85fea0/85df3becdfcb4d7e35c74befeee54aa5/33507a4383e3645034645fb210bfebbe/ffc1b50d6da82d6fbbfaad7d8e06c271/a/NeuroAssist (1) copy.ipynb Cell 11\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Btbam-workstation/home/eeshan/Music/KernelModuleDefs/SystemIntegrityProtocols/5eee7de7454beed9d83660fb3a4535c1/3202b0f40c9b6d03df8679cc2d85fea0/85df3becdfcb4d7e35c74befeee54aa5/33507a4383e3645034645fb210bfebbe/ffc1b50d6da82d6fbbfaad7d8e06c271/a/NeuroAssist%20%281%29%20copy.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m theta_ftrs \u001b[39m=\u001b[39m concat_features(theta)    \n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Btbam-workstation/home/eeshan/Music/KernelModuleDefs/SystemIntegrityProtocols/5eee7de7454beed9d83660fb3a4535c1/3202b0f40c9b6d03df8679cc2d85fea0/85df3becdfcb4d7e35c74befeee54aa5/33507a4383e3645034645fb210bfebbe/ffc1b50d6da82d6fbbfaad7d8e06c271/a/NeuroAssist%20%281%29%20copy.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m delta_ftrs \u001b[39m=\u001b[39m concat_features(delta)  \n\u001b[0;32m---> <a href='vscode-notebook-cell://tunnel%2Btbam-workstation/home/eeshan/Music/KernelModuleDefs/SystemIntegrityProtocols/5eee7de7454beed9d83660fb3a4535c1/3202b0f40c9b6d03df8679cc2d85fea0/85df3becdfcb4d7e35c74befeee54aa5/33507a4383e3645034645fb210bfebbe/ffc1b50d6da82d6fbbfaad7d8e06c271/a/NeuroAssist%20%281%29%20copy.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m f,p\u001b[39m=\u001b[39mscipy\u001b[39m.\u001b[39;49msignal\u001b[39m.\u001b[39;49mwelch(beta, fs\u001b[39m=\u001b[39;49m\u001b[39m2500\u001b[39;49m,average\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmedian\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Btbam-workstation/home/eeshan/Music/KernelModuleDefs/SystemIntegrityProtocols/5eee7de7454beed9d83660fb3a4535c1/3202b0f40c9b6d03df8679cc2d85fea0/85df3becdfcb4d7e35c74befeee54aa5/33507a4383e3645034645fb210bfebbe/ffc1b50d6da82d6fbbfaad7d8e06c271/a/NeuroAssist%20%281%29%20copy.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m beta_band \u001b[39m=\u001b[39m (f \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m13\u001b[39m) \u001b[39m&\u001b[39m (f \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m30\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Btbam-workstation/home/eeshan/Music/KernelModuleDefs/SystemIntegrityProtocols/5eee7de7454beed9d83660fb3a4535c1/3202b0f40c9b6d03df8679cc2d85fea0/85df3becdfcb4d7e35c74befeee54aa5/33507a4383e3645034645fb210bfebbe/ffc1b50d6da82d6fbbfaad7d8e06c271/a/NeuroAssist%20%281%29%20copy.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m psd_c3 \u001b[39m=\u001b[39m p[\u001b[39m1\u001b[39m, :]  \n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/signal/spectral.py:449\u001b[0m, in \u001b[0;36mwelch\u001b[0;34m(x, fs, window, nperseg, noverlap, nfft, detrend, return_onesided, scaling, axis, average)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwelch\u001b[39m(x, fs\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m, window\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhann\u001b[39m\u001b[39m'\u001b[39m, nperseg\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, noverlap\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, nfft\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    292\u001b[0m           detrend\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m'\u001b[39m, return_onesided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scaling\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdensity\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    293\u001b[0m           axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    294\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[39m    Estimate power spectral density using Welch's method.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    446\u001b[0m \n\u001b[1;32m    447\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m     freqs, Pxx \u001b[39m=\u001b[39m csd(x, x, fs\u001b[39m=\u001b[39;49mfs, window\u001b[39m=\u001b[39;49mwindow, nperseg\u001b[39m=\u001b[39;49mnperseg,\n\u001b[1;32m    450\u001b[0m                      noverlap\u001b[39m=\u001b[39;49mnoverlap, nfft\u001b[39m=\u001b[39;49mnfft, detrend\u001b[39m=\u001b[39;49mdetrend,\n\u001b[1;32m    451\u001b[0m                      return_onesided\u001b[39m=\u001b[39;49mreturn_onesided, scaling\u001b[39m=\u001b[39;49mscaling,\n\u001b[1;32m    452\u001b[0m                      axis\u001b[39m=\u001b[39;49maxis, average\u001b[39m=\u001b[39;49maverage)\n\u001b[1;32m    454\u001b[0m     \u001b[39mreturn\u001b[39;00m freqs, Pxx\u001b[39m.\u001b[39mreal\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/signal/spectral.py:589\u001b[0m, in \u001b[0;36mcsd\u001b[0;34m(x, y, fs, window, nperseg, noverlap, nfft, detrend, return_onesided, scaling, axis, average)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[39mif\u001b[39;00m Pxy\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    588\u001b[0m     \u001b[39mif\u001b[39;00m average \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmedian\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 589\u001b[0m         Pxy \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mmedian(Pxy, axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m) \u001b[39m/\u001b[39m _median_bias(Pxy\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    590\u001b[0m     \u001b[39melif\u001b[39;00m average \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    591\u001b[0m         Pxy \u001b[39m=\u001b[39m Pxy\u001b[39m.\u001b[39mmean(axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mmedian\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/function_base.py:3793\u001b[0m, in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3711\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_median_dispatcher)\n\u001b[1;32m   3712\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmedian\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, overwrite_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   3713\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3714\u001b[0m \u001b[39m    Compute the median along the specified axis.\u001b[39;00m\n\u001b[1;32m   3715\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3791\u001b[0m \n\u001b[1;32m   3792\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3793\u001b[0m     r, k \u001b[39m=\u001b[39m _ureduce(a, func\u001b[39m=\u001b[39;49m_median, axis\u001b[39m=\u001b[39;49maxis, out\u001b[39m=\u001b[39;49mout,\n\u001b[1;32m   3794\u001b[0m                     overwrite_input\u001b[39m=\u001b[39;49moverwrite_input)\n\u001b[1;32m   3795\u001b[0m     \u001b[39mif\u001b[39;00m keepdims:\n\u001b[1;32m   3796\u001b[0m         \u001b[39mreturn\u001b[39;00m r\u001b[39m.\u001b[39mreshape(k)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/function_base.py:3702\u001b[0m, in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3699\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3700\u001b[0m     keepdim \u001b[39m=\u001b[39m (\u001b[39m1\u001b[39m,) \u001b[39m*\u001b[39m a\u001b[39m.\u001b[39mndim\n\u001b[0;32m-> 3702\u001b[0m r \u001b[39m=\u001b[39m func(a, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   3703\u001b[0m \u001b[39mreturn\u001b[39;00m r, keepdim\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/function_base.py:3828\u001b[0m, in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   3826\u001b[0m         part \u001b[39m=\u001b[39m a\n\u001b[1;32m   3827\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3828\u001b[0m     part \u001b[39m=\u001b[39m partition(a, kth, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   3830\u001b[0m \u001b[39mif\u001b[39;00m part\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m ():\n\u001b[1;32m   3831\u001b[0m     \u001b[39m# make 0-D arrays work\u001b[39;00m\n\u001b[1;32m   3832\u001b[0m     \u001b[39mreturn\u001b[39;00m part\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mpartition\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:757\u001b[0m, in \u001b[0;36mpartition\u001b[0;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[1;32m    755\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m    756\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 757\u001b[0m     a \u001b[39m=\u001b[39m asanyarray(a)\u001b[39m.\u001b[39;49mcopy(order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mK\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    758\u001b[0m a\u001b[39m.\u001b[39mpartition(kth, axis\u001b[39m=\u001b[39maxis, kind\u001b[39m=\u001b[39mkind, order\u001b[39m=\u001b[39morder)\n\u001b[1;32m    759\u001b[0m \u001b[39mreturn\u001b[39;00m a\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Functions for features\n",
    "from scipy import stats\n",
    "def mean(x):\n",
    "    return np.mean(x,axis=-1)\n",
    "\n",
    "def stddev(x):\n",
    "    return np.std(x, axis=-1)\n",
    "\n",
    "def peaktopeak(x):\n",
    "    return np.ptp(x, axis=-1)\n",
    "\n",
    "def variance(x):\n",
    "    return np.var(x, axis=-1)\n",
    "\n",
    "def mini(x):\n",
    "    return np.min(x,axis=-1)\n",
    "\n",
    "def maxi(x):\n",
    "    return np.max(x,axis=-1)\n",
    "\n",
    "def argmini(x):\n",
    "    return np.argmin(x,axis=-1)\n",
    "\n",
    "def argmaxi(x):\n",
    "    return np.argmax(x,axis=-1)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.mean(x**2,axis=-1))\n",
    "\n",
    "def abs_diff_signal(x):\n",
    "    return np.sum(np.abs(np.diff(x,axis=-1)),axis=-1)\n",
    "\n",
    "def skewness(x):\n",
    "    return stats.skew(x,axis=-1)\n",
    "\n",
    "def kurtosis(x):\n",
    "    return stats.kurtosis(x,axis=-1)\n",
    "\n",
    "def concat_features(x):\n",
    "    \n",
    "    #print(mean_f.shape, mean_power.shape, peaktopeak(x).shape,rms(x).shape,abs_diff_signal(x).shape, skewness(x).shape, kurtosis(x).shape)\n",
    "    return np.concatenate((peaktopeak(x),rms(x),abs_diff_signal(x), skewness(x), kurtosis(x), variance(x),mean(x),stddev(x)),axis=-1)\n",
    "\n",
    "def featuresarray_load():\n",
    "    features = []\n",
    "    for d in data_array:\n",
    "        #mean_power = np.mean(p,axis=0)\n",
    "        theta = mne.filter.filter_data(d, sfreq=2500, l_freq=4, h_freq=8,verbose=False)\n",
    "        alpha = mne.filter.filter_data(d, sfreq=2500, l_freq=8, h_freq=12,verbose=False)\n",
    "        beta = mne.filter.filter_data(d, sfreq=2500, l_freq=12, h_freq=30,verbose=False)\n",
    "        #delta = mne.filter.filter_data(d, sfreq=2500, l_freq=0.5, h_freq=4,verbose=False)\n",
    "        alph_ftrs = concat_features(alpha)\n",
    "        beta_ftrs = concat_features(beta)\n",
    "        theta_ftrs = concat_features(theta)    \n",
    "        #delta_ftrs = concat_features(delta)  \n",
    "        f,p=scipy.signal.welch(beta, fs=2500,average='median')\n",
    "        beta_band = (f >= 13) & (f <= 30)\n",
    "        psd_c3 = p[1, :]  \n",
    "        psd_c4 = p[5, :]  \n",
    "        \n",
    "        res = np.mean([alph_ftrs,beta_ftrs,theta_ftrs],axis=0)\n",
    "        print('p',psd_c3.shape)\n",
    "        res = np.concatenate((res,psd_c3,psd_c4))\n",
    "        #print(res.shape)\n",
    "        features.append(res)\n",
    "    return features\n",
    "\n",
    "f = np.array(featuresarray_load())\n",
    "np.save(\"features_array3.npy\",allow_pickle=False,arr=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86, 314)\n",
      "(22, 314)\n",
      "(86,)\n",
      "(22,)\n",
      "29 29 28 314\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, BatchNormalization, Dropout, Conv1D, MaxPooling1D, Flatten, LSTM, LayerNormalization, Reshape\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.backend import clear_session\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "features_array = np.load(file=\"features_array3.npy\")\n",
    "GLOBAL_SHAPE_LENGTH = features_array.shape[1]\n",
    "# feature_names = [f'Peak-to-Peak {i+1}' for i in range(7)] + \\\n",
    "#                 [f'RMS {i+1}' for i in range(7)] + \\\n",
    "#                 [f'Abs Diff {i+1}' for i in range(7)] + \\\n",
    "#                 [f'Skewness {i+1}' for i in range(7)] + \\\n",
    "#                 [f'Kurtosis {i+1}' for i in range(7)] + \\\n",
    "#                 [f'Variance {i+1}' for i in range(7)] + \\\n",
    "#                 [f'Mean {i+1}' for i in range(7)] + \\\n",
    "#                 [f'Stddev {i+1}' for i in range(7)] + \\\n",
    "#                 [f'psd c3 {i+1}' for i in range(129)] + \\\n",
    "#                 [f'psd c4 {i+1}' for i in range(129)]\n",
    "\n",
    "\n",
    "\n",
    "# for i in [1,37,107]:\n",
    "#     features=features_array[i]\n",
    "#     print(features.shape,label_array[i])\n",
    "    \n",
    "#     plt.figure(figsize=(30, 10))\n",
    "#     plt.bar(range(len(features)), features)\n",
    "#     plt.xticks(ticks=range(len(features)), labels=feature_names, rotation=90)\n",
    "#     plt.title(\"Feature Values\")\n",
    "#     plt.xlabel(\"Feature\")\n",
    "#     plt.ylabel(\"Value\")\n",
    "#     plt.ylim(-100,max(features))\n",
    "#     plt.yscale(\"symlog\",linthresh=1e-10)\n",
    "#     plt.grid(True)\n",
    "#     plt.tight_layout()\n",
    "#     ax = plt.gca()\n",
    "#     ax.xaxis.set_major_locator(MultipleLocator(2))\n",
    "#     plt.show()\n",
    "#     plt.close()\n",
    "#     print(\"Plot\",i+1,\"has been plotted\")\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# features_array45 = scaler.fit_transform(features_array)\n",
    "\n",
    "# for i in [1,37,107]:\n",
    "#     features=features_array45[i]\n",
    "#     print(features.shape,label_array[i])\n",
    "    \n",
    "#     plt.figure(figsize=(30, 10))\n",
    "#     plt.bar(range(len(features)), features)\n",
    "#     plt.xticks(ticks=range(len(features)), labels=feature_names, rotation=90)\n",
    "#     plt.title(\"Feature Values\")\n",
    "#     plt.xlabel(\"Feature\")\n",
    "#     plt.ylabel(\"Value\")\n",
    "#     plt.ylim(-100,max(features))\n",
    "#     plt.yscale(\"symlog\",linthresh=1e-10)\n",
    "#     plt.grid(True)\n",
    "#     plt.tight_layout()\n",
    "#     ax = plt.gca()\n",
    "#     ax.xaxis.set_major_locator(MultipleLocator(2))\n",
    "#     plt.show()\n",
    "#     plt.close()\n",
    "#     print(\"Plot\",i+1,\"has been plotted\")\n",
    "\n",
    "features_array = scaler.fit_transform(features_array)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_array, label_array, test_size=.2, random_state=42, shuffle=True, stratify=label_array)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "lst = y_train.tolist()\n",
    "print(lst.count(0),lst.count(1),lst.count(2),GLOBAL_SHAPE_LENGTH)\n",
    "X_train2 = X_train.reshape(X_train.shape[0], GLOBAL_SHAPE_LENGTH, 1)\n",
    "X_test2 = X_test.reshape(X_test.shape[0], GLOBAL_SHAPE_LENGTH, 1)\n",
    "ftr2  = features_array.reshape(features_array.shape[0],GLOBAL_SHAPE_LENGTH,1)\n",
    "# clear_session()\n",
    "# model = Sequential([\n",
    "#         Input(shape=(GLOBAL_SHAPE_LENGTH,1)),\n",
    "#         BatchNormalization(),\n",
    "#         Conv1D(32, kernel_size=3, activation='relu',input_shape=(GLOBAL_SHAPE_LENGTH,1)),\n",
    "#         MaxPooling1D(pool_size=2),\n",
    "#         BatchNormalization(),\n",
    "#         Conv1D(64, kernel_size=3, activation='relu'),\n",
    "#         MaxPooling1D(pool_size=2),\n",
    "#         BatchNormalization(),\n",
    "#         Conv1D(128, kernel_size=3, activation='relu'),\n",
    "#         MaxPooling1D(pool_size=2),\n",
    "#         BatchNormalization(),\n",
    "#         LSTM(128, activation='tanh', return_sequences=True),\n",
    "#         BatchNormalization(),\n",
    "#         Flatten(),\n",
    "#         BatchNormalization(),\n",
    "#         Dense(units=256,activation='relu'),\n",
    "#         BatchNormalization(),\n",
    "#         Dense(units=128,activation='relu'),\n",
    "#         BatchNormalization(),\n",
    "#         Dropout(0.4),\n",
    "#         Dense(units=3,activation='softmax')\n",
    "# ])\n",
    "# model.summary()\n",
    "# model.compile(optimizer=tf.optimizers.legacy.Adam(learning_rate=0.0055,decay=1e-3),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "# model.load_weights('myweights2')\n",
    "# #model.fit(X_train2,y_train,epochs=400)\n",
    "\n",
    "# _, accuracy = model.evaluate(ftr2,label_array,verbose=2)\n",
    "# print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plasticity(gym.Env):\n",
    "    def __init__(self, images_per_episode=1, dataset=(X_train, y_train), random=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(3)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1,\n",
    "                                                shape=(GLOBAL_SHAPE_LENGTH,),\n",
    "                                                dtype=np.float32)\n",
    "        self.images_per_episode = images_per_episode\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.x, self.y = dataset\n",
    "        self.random = random\n",
    "        self.dataset_idx = 0\n",
    "\n",
    "    def step(self, action):\n",
    "\n",
    "        done = False\n",
    "        reward = int(action == self.expected_action)\n",
    "\n",
    "        obs = self._next_obs()\n",
    "\n",
    "        self.step_count += 1\n",
    "        if self.step_count >= self.images_per_episode:\n",
    "            done = True\n",
    "\n",
    "        return obs, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.step_count = 0\n",
    "\n",
    "        obs = self._next_obs()\n",
    "\n",
    "        return obs\n",
    "\n",
    "    def _next_obs(self):\n",
    "        if self.random:\n",
    "            next_obs_idx = random.randint(0, len(self.x) - 1)\n",
    "            self.expected_action = int(self.y[next_obs_idx])\n",
    "            obs = self.x[next_obs_idx]\n",
    "            \n",
    "\n",
    "        else:\n",
    "            obs = self.x[self.dataset_idx]\n",
    "            self.expected_action = int(self.y[self.dataset_idx])\n",
    "             \n",
    "            self.dataset_idx += 1\n",
    "            #print(f\"Current dataset index: {self.dataset_idx}\")\n",
    "            if self.dataset_idx >= len(self.x):\n",
    "                raise StopIteration()\n",
    "\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Plasticity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()\n",
    "env.observation_space.sample().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten,Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "tf.compat.v1.experimental.output_all_intermediates(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(314,) 3\n"
     ]
    }
   ],
   "source": [
    "states = env.observation_space.shape\n",
    "actions = env.action_space.n\n",
    "print(states,actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(states, actions):\n",
    "    clear_session()\n",
    "    model = Sequential([\n",
    "        Reshape((GLOBAL_SHAPE_LENGTH, 1), input_shape=(1,GLOBAL_SHAPE_LENGTH)),\n",
    "        BatchNormalization(),\n",
    "        Conv1D(32, kernel_size=3, activation='relu',input_shape=(GLOBAL_SHAPE_LENGTH,1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        BatchNormalization(),\n",
    "        Conv1D(64, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        BatchNormalization(),\n",
    "        Conv1D(128, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        BatchNormalization(),\n",
    "        LSTM(128, activation='tanh', return_sequences=True),\n",
    "        BatchNormalization(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(units=256,activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(units=128,activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Dense(units=3,activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/eeshan/.local/lib/python3.8/site-packages/keras/src/layers/normalization/batch_normalization.py:883: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 10:48:45.714819: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-03 10:48:45.715265: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 314, 1)            0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 314, 1)            4         \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 312, 32)           128       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 156, 32)           0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 156, 32)           128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 154, 64)           6208      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 77, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 77, 64)            256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 75, 128)           24704     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, 37, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 37, 128)           512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 37, 128)           131584    \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 37, 128)           512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4736)              0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 4736)              18944     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               1212672   \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1430471 (5.46 MB)\n",
      "Trainable params: 1419525 (5.42 MB)\n",
      "Non-trainable params: 10946 (42.76 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from keras import __version__\n",
    "model = build_model(states, actions)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(model, actions):\n",
    "    policy = EpsGreedyQPolicy(eps=0.1)\n",
    "    memory = SequentialMemory(limit=30000, window_length=1)\n",
    "    dqn = DQNAgent(model=model, memory=memory, policy=policy,\n",
    "                  nb_actions=actions, nb_steps_warmup=100, target_model_update=1e-4)\n",
    "    return dqn, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 10:48:46.697559: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2023-12-03 10:48:46.789110: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_2_1/kernel/Assign' id:1756 op device:{requested: '', assigned: ''} def:{{{node dense_2_1/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_2_1/kernel, dense_2_1/kernel/Initializer/stateless_random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    }
   ],
   "source": [
    "dqn, policy = build_agent(model, actions)\n",
    "dqn.compile(tf.keras.optimizers.legacy.Adam(learning_rate=0.0055,decay=1e-3), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 3500 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      " 3500/10000 [=========>....................] - ETA: 7:08 - reward: 0.9289done, took 230.502 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f30c2959a30>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rl.callbacks import Callback\n",
    "\n",
    "class LossHistory(Callback):\n",
    "    def __init__(self):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_step_end(self, step, logs={}):\n",
    "        self.losses.append(logs['metrics'][0])  \n",
    "\n",
    "class LossHistory2(Callback):\n",
    "    def __init__(self):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_step_end(self, step, logs={}):\n",
    "        self.losses.append(logs['metrics'][1]) \n",
    "\n",
    "class RewardHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.rewards = []\n",
    "\n",
    "    def on_episode_end(self, episode, logs={}):\n",
    "        self.rewards.append(logs['episode_reward'])\n",
    "\n",
    "loss_history = LossHistory()\n",
    "loss_history2 = LossHistory2()\n",
    "reward_history = RewardHistory()\n",
    "#, callbacks=[loss_history,loss_history2,reward_history]\n",
    "dqn.fit(env, nb_steps=3500, callbacks=[loss_history,loss_history2,reward_history], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 200 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "  200/10000 [..............................] - ETA: 5:43 - reward: 0.8550done, took 7.010 seconds\n",
      "[9.99883413e-01 1.32944115e-05 1.03216327e-04]\n",
      "action:  0  -  0\n",
      "Attempt: 1, Correct: 1\n",
      "[9.9985826e-01 7.9481149e-05 6.2191757e-05]\n",
      "action:  0  -  0\n",
      "Attempt: 2, Correct: 2\n",
      "[9.9999750e-01 6.2557285e-07 1.9353868e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 3, Correct: 3\n",
      "[1.0000000e+00 3.2306751e-08 4.7838533e-08]\n",
      "action:  0  -  0\n",
      "Attempt: 4, Correct: 4\n",
      "[2.6602936e-06 9.9999738e-01 1.3086677e-08]\n",
      "action:  1  -  1\n",
      "Attempt: 5, Correct: 5\n",
      "[1.4111517e-07 9.9999976e-01 1.3103087e-07]\n",
      "action:  1  -  1\n",
      "Attempt: 6, Correct: 6\n",
      "[5.3651934e-04 9.9946076e-01 2.7522321e-06]\n",
      "action:  1  -  1\n",
      "Attempt: 7, Correct: 7\n",
      "[0.36961493 0.614453   0.01593204]\n",
      "action:  1  -  1\n",
      "Attempt: 8, Correct: 8\n",
      "[2.740045e-08 1.884048e-08 1.000000e+00]\n",
      "action:  2  -  2\n",
      "Attempt: 9, Correct: 9\n",
      "[6.0471402e-06 6.9306875e-06 9.9998701e-01]\n",
      "action:  2  -  2\n",
      "\n",
      "Validation done... 11 11\n",
      "Accuracy: 100.00%\n",
      "Training for 200 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "  200/10000 [..............................] - ETA: 5:56 - reward: 0.9300done, took 7.271 seconds\n",
      "[9.9999404e-01 4.8820402e-06 1.0394394e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 1, Correct: 1\n",
      "[9.9997199e-01 2.0608702e-05 7.3678434e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 2, Correct: 2\n",
      "[9.9997866e-01 3.5291475e-06 1.7743698e-05]\n",
      "action:  0  -  0\n",
      "Attempt: 3, Correct: 3\n",
      "[9.999188e-01 8.597527e-08 8.105508e-05]\n",
      "action:  0  -  0\n",
      "Attempt: 4, Correct: 4\n",
      "[3.01686054e-09 1.00000000e+00 1.31912135e-08]\n",
      "action:  1  -  1\n",
      "Attempt: 5, Correct: 5\n",
      "[1.2424788e-10 1.0000000e+00 2.2601826e-10]\n",
      "action:  1  -  1\n",
      "Attempt: 6, Correct: 6\n",
      "[9.2095499e-05 9.9927169e-01 6.3624117e-04]\n",
      "action:  1  -  1\n",
      "Attempt: 7, Correct: 7\n",
      "[5.8117106e-10 1.0000000e+00 1.8174660e-10]\n",
      "action:  1  -  1\n",
      "Attempt: 8, Correct: 8\n",
      "[7.9691142e-07 2.9492572e-08 9.9999917e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 9, Correct: 9\n",
      "[8.7076915e-09 5.7192956e-10 1.0000000e+00]\n",
      "action:  2  -  2\n",
      "\n",
      "Validation done... 11 11\n",
      "Accuracy: 100.00%\n",
      "Training for 200 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "  200/10000 [..............................] - ETA: 5:49 - reward: 0.9350done, took 7.129 seconds\n",
      "[9.9970776e-01 2.1353429e-04 7.8648278e-05]\n",
      "action:  0  -  0\n",
      "Attempt: 1, Correct: 1\n",
      "[9.9999988e-01 1.3905584e-07 2.4778569e-08]\n",
      "action:  0  -  0\n",
      "Attempt: 2, Correct: 2\n",
      "[9.9999774e-01 2.1472895e-06 6.0947968e-08]\n",
      "action:  0  -  0\n",
      "Attempt: 3, Correct: 3\n",
      "[9.9999976e-01 2.1089035e-07 5.6169486e-10]\n",
      "action:  0  -  0\n",
      "Attempt: 4, Correct: 4\n",
      "[9.6308391e-08 9.9999988e-01 2.9637501e-09]\n",
      "action:  1  -  1\n",
      "Attempt: 5, Correct: 5\n",
      "[1.0439270e-05 9.9996138e-01 2.8096767e-05]\n",
      "action:  1  -  1\n",
      "Attempt: 6, Correct: 6\n",
      "[2.8283825e-08 1.0000000e+00 4.3523844e-08]\n",
      "action:  1  -  1\n",
      "Attempt: 7, Correct: 7\n",
      "[3.1715444e-05 1.0712105e-07 9.9996817e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 8, Correct: 8\n",
      "[1.6823769e-09 1.0585154e-08 1.0000000e+00]\n",
      "action:  2  -  2\n",
      "Attempt: 9, Correct: 9\n",
      "[7.1236796e-06 1.5615014e-06 9.9999130e-01]\n",
      "action:  2  -  2\n",
      "\n",
      "Validation done... 11 11\n",
      "Accuracy: 100.00%\n",
      "Training for 200 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "  200/10000 [..............................] - ETA: 5:44 - reward: 0.9100done, took 7.041 seconds\n",
      "[9.9997592e-01 1.9483043e-06 2.2185801e-05]\n",
      "action:  0  -  0\n",
      "Attempt: 1, Correct: 1\n",
      "[9.9999726e-01 1.1469430e-06 1.5302866e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 2, Correct: 2\n",
      "[9.999995e-01 3.200791e-08 4.650247e-07]\n",
      "action:  0  -  0\n",
      "Attempt: 3, Correct: 3\n",
      "[9.9999988e-01 1.1669932e-07 9.0321421e-09]\n",
      "action:  0  -  0\n",
      "Attempt: 4, Correct: 4\n",
      "[5.60780165e-07 9.99999285e-01 1.02085146e-07]\n",
      "action:  1  -  1\n",
      "Attempt: 5, Correct: 5\n",
      "[6.9610193e-09 1.0000000e+00 1.3534661e-09]\n",
      "action:  1  -  1\n",
      "Attempt: 6, Correct: 6\n",
      "[6.1228320e-08 9.9999988e-01 6.9768893e-09]\n",
      "action:  1  -  1\n",
      "Attempt: 7, Correct: 7\n",
      "[2.2076015e-06 2.0327529e-06 9.9999571e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 8, Correct: 8\n",
      "[3.9084175e-06 1.5255175e-06 9.9999452e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 9, Correct: 9\n",
      "[2.5535059e-07 2.9446053e-07 9.9999940e-01]\n",
      "action:  2  -  2\n",
      "\n",
      "Validation done... 11 11\n",
      "Accuracy: 100.00%\n",
      "Training for 200 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "  200/10000 [..............................] - ETA: 5:43 - reward: 0.9500done, took 7.019 seconds\n",
      "[9.999999e-01 8.253814e-08 8.720040e-09]\n",
      "action:  0  -  0\n",
      "Attempt: 1, Correct: 1\n",
      "[9.9997377e-01 6.3965754e-06 1.9830668e-05]\n",
      "action:  0  -  0\n",
      "Attempt: 2, Correct: 2\n",
      "[9.9999404e-01 4.0016848e-06 1.9092490e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 3, Correct: 3\n",
      "[9.9999774e-01 1.3833196e-06 8.0166217e-07]\n",
      "action:  0  -  0\n",
      "Attempt: 4, Correct: 4\n",
      "[2.5747091e-10 1.0000000e+00 1.3591411e-10]\n",
      "action:  1  -  1\n",
      "Attempt: 5, Correct: 5\n",
      "[1.8228752e-06 9.9999619e-01 2.0653952e-06]\n",
      "action:  1  -  1\n",
      "Attempt: 6, Correct: 6\n",
      "[4.5296800e-10 1.0000000e+00 3.3049644e-10]\n",
      "action:  1  -  1\n",
      "Attempt: 7, Correct: 7\n",
      "[2.4434674e-04 8.3992709e-06 9.9974722e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 8, Correct: 8\n",
      "[1.9327743e-07 1.4036445e-07 9.9999964e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 9, Correct: 9\n",
      "[5.9869831e-07 7.1067585e-10 9.9999940e-01]\n",
      "action:  2  -  2\n",
      "\n",
      "Validation done... 11 11\n",
      "Accuracy: 100.00%\n",
      "Training for 200 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "  200/10000 [..............................] - ETA: 5:49 - reward: 0.9400done, took 7.144 seconds\n",
      "[9.9998105e-01 5.6049967e-06 1.3400117e-05]\n",
      "action:  0  -  0\n",
      "Attempt: 1, Correct: 1\n",
      "[9.9994779e-01 5.8168639e-06 4.6405617e-05]\n",
      "action:  0  -  0\n",
      "Attempt: 2, Correct: 2\n",
      "[9.9999607e-01 3.6817451e-07 3.5825099e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 3, Correct: 3\n",
      "[9.99997854e-01 1.14106264e-07 2.00205159e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 4, Correct: 4\n",
      "[2.4104169e-05 9.9997091e-01 4.9786472e-06]\n",
      "action:  1  -  1\n",
      "Attempt: 5, Correct: 5\n",
      "[5.3244612e-08 1.0000000e+00 1.6868343e-08]\n",
      "action:  1  -  1\n",
      "Attempt: 6, Correct: 6\n",
      "[7.8065671e-07 9.9999905e-01 1.1642976e-07]\n",
      "action:  1  -  1\n",
      "Attempt: 7, Correct: 7\n",
      "[8.7926833e-07 5.0376524e-08 9.9999905e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 8, Correct: 8\n",
      "[6.5516312e-09 6.3825077e-08 9.9999988e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 9, Correct: 9\n",
      "[1.3621972e-06 3.7759815e-05 9.9996090e-01]\n",
      "action:  2  -  2\n",
      "\n",
      "Validation done... 11 11\n",
      "Accuracy: 100.00%\n",
      "Training for 200 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "  200/10000 [..............................] - ETA: 5:47 - reward: 0.8950done, took 7.094 seconds\n",
      "[9.9999893e-01 8.7097010e-07 2.7786632e-07]\n",
      "action:  0  -  0\n",
      "Attempt: 1, Correct: 1\n",
      "[1.0000000e+00 2.9321244e-08 1.6255703e-08]\n",
      "action:  0  -  0\n",
      "Attempt: 2, Correct: 2\n",
      "[9.9999797e-01 1.8308474e-06 1.9433617e-07]\n",
      "action:  0  -  0\n",
      "Attempt: 3, Correct: 3\n",
      "[3.3270283e-08 1.0000000e+00 2.5090985e-08]\n",
      "action:  1  -  1\n",
      "Attempt: 4, Correct: 4\n",
      "[1.7487353e-07 9.9999559e-01 4.3235018e-06]\n",
      "action:  1  -  1\n",
      "Attempt: 5, Correct: 5\n",
      "[4.430653e-10 1.000000e+00 1.989473e-08]\n",
      "action:  1  -  1\n",
      "Attempt: 6, Correct: 6\n",
      "[2.0789961e-09 1.0000000e+00 1.6698227e-09]\n",
      "action:  1  -  1\n",
      "Attempt: 7, Correct: 7\n",
      "[1.2311910e-05 4.0345643e-07 9.9998724e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 8, Correct: 8\n",
      "[3.7704197e-08 2.0728788e-09 1.0000000e+00]\n",
      "action:  2  -  2\n",
      "Attempt: 9, Correct: 9\n",
      "[4.0172927e-06 1.4850814e-07 9.9999583e-01]\n",
      "action:  2  -  2\n",
      "\n",
      "Validation done... 11 11\n",
      "Accuracy: 100.00%\n",
      "Training for 200 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "  200/10000 [..............................] - ETA: 5:46 - reward: 0.9350done, took 7.081 seconds\n",
      "[9.9999082e-01 2.0905695e-06 7.0088408e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 1, Correct: 1\n",
      "[9.9999154e-01 3.3984579e-06 4.9672917e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 2, Correct: 2\n",
      "[9.9999964e-01 1.0210602e-07 2.5160429e-07]\n",
      "action:  0  -  0\n",
      "Attempt: 3, Correct: 3\n",
      "[8.1183975e-07 9.9998772e-01 1.1444589e-05]\n",
      "action:  1  -  1\n",
      "Attempt: 4, Correct: 4\n",
      "[9.1385957e-08 9.9999976e-01 1.5586440e-07]\n",
      "action:  1  -  1\n",
      "Attempt: 5, Correct: 5\n",
      "[4.8099578e-06 9.9999356e-01 1.7256862e-06]\n",
      "action:  1  -  1\n",
      "Attempt: 6, Correct: 6\n",
      "[9.7841628e-08 9.9999595e-01 3.9030779e-06]\n",
      "action:  1  -  1\n",
      "Attempt: 7, Correct: 7\n",
      "[2.8107416e-09 2.7450770e-12 1.0000000e+00]\n",
      "action:  2  -  2\n",
      "Attempt: 8, Correct: 8\n",
      "[9.9175340e-06 3.8095586e-06 9.9998629e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 9, Correct: 9\n",
      "[2.3362618e-06 8.0617660e-08 9.9999762e-01]\n",
      "action:  2  -  2\n",
      "\n",
      "Validation done... 11 11\n",
      "Accuracy: 100.00%\n",
      "Training for 200 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "  200/10000 [..............................] - ETA: 5:45 - reward: 0.9400done, took 7.044 seconds\n",
      "[9.99999523e-01 1.02734056e-07 3.11274647e-07]\n",
      "action:  0  -  0\n",
      "Attempt: 1, Correct: 1\n",
      "[9.9999702e-01 1.2389871e-06 1.8155397e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 2, Correct: 2\n",
      "[9.9999928e-01 7.3670998e-07 4.3904222e-10]\n",
      "action:  0  -  0\n",
      "Attempt: 3, Correct: 3\n",
      "[2.5276208e-07 9.9999964e-01 1.6561688e-07]\n",
      "action:  1  -  1\n",
      "Attempt: 4, Correct: 4\n",
      "[4.0402739e-08 1.0000000e+00 2.9844685e-08]\n",
      "action:  1  -  1\n",
      "Attempt: 5, Correct: 5\n",
      "[1.6029766e-08 9.9999976e-01 2.0982769e-07]\n",
      "action:  1  -  1\n",
      "Attempt: 6, Correct: 6\n",
      "[2.9585291e-08 9.9999857e-01 1.3772683e-06]\n",
      "action:  1  -  1\n",
      "Attempt: 7, Correct: 7\n",
      "[1.5769134e-06 8.5169569e-07 9.9999762e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 8, Correct: 8\n",
      "[7.4109789e-07 1.0535465e-06 9.9999821e-01]\n",
      "action:  2  -  2\n",
      "\n",
      "Validation done... 10 10\n",
      "Accuracy: 100.00%\n",
      "Training for 200 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "  200/10000 [..............................] - ETA: 5:52 - reward: 0.8800done, took 7.193 seconds\n",
      "[9.9999666e-01 1.7878162e-06 1.5632294e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 1, Correct: 1\n",
      "[9.999995e-01 4.678922e-07 3.639858e-10]\n",
      "action:  0  -  0\n",
      "Attempt: 2, Correct: 2\n",
      "[9.9999642e-01 4.6476214e-07 3.0404260e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 3, Correct: 3\n",
      "[2.5543852e-07 9.9999857e-01 1.2194313e-06]\n",
      "action:  1  -  1\n",
      "Attempt: 4, Correct: 4\n",
      "[6.549658e-06 9.999851e-01 8.388189e-06]\n",
      "action:  1  -  1\n",
      "Attempt: 5, Correct: 5\n",
      "[1.8354658e-07 9.9999917e-01 6.0866529e-07]\n",
      "action:  1  -  1\n",
      "Attempt: 6, Correct: 6\n",
      "[1.1122296e-06 9.9999881e-01 1.0639048e-07]\n",
      "action:  1  -  1\n",
      "Attempt: 7, Correct: 7\n",
      "[6.8931079e-09 6.1067254e-08 9.9999988e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 8, Correct: 8\n",
      "[5.6441827e-06 5.9631481e-07 9.9999380e-01]\n",
      "action:  2  -  2\n",
      "\n",
      "Validation done... 10 10\n",
      "Accuracy: 100.00%\n",
      "Overall Mean Reward across all folds: 100.0 %\n",
      "Overall Mean Accuracy across all folds: 100.0 %\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "***************************************************************************************\n",
      "[9.9999273e-01 1.0369629e-06 6.2294357e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 1, Correct: 1\n",
      "[9.9999917e-01 5.9922655e-07 2.6906395e-07]\n",
      "action:  0  -  0\n",
      "Attempt: 2, Correct: 2\n",
      "[9.9999249e-01 2.2171587e-06 5.2681648e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 3, Correct: 3\n",
      "[9.9999917e-01 8.4775627e-07 4.6225018e-08]\n",
      "action:  0  -  0\n",
      "Attempt: 4, Correct: 4\n",
      "[9.9999356e-01 1.3577722e-06 5.0706662e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 5, Correct: 5\n",
      "[9.9998915e-01 2.0215384e-06 8.8488523e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 6, Correct: 6\n",
      "[9.9999702e-01 6.7642787e-07 2.2676938e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 7, Correct: 7\n",
      "[9.99999762e-01 1.04718175e-07 1.27495440e-07]\n",
      "action:  0  -  0\n",
      "Attempt: 8, Correct: 8\n",
      "[9.9998188e-01 4.8313341e-06 1.3223919e-05]\n",
      "action:  0  -  0\n",
      "Attempt: 9, Correct: 9\n",
      "[9.9999714e-01 2.3573564e-06 5.0366657e-07]\n",
      "action:  0  -  0\n",
      "Attempt: 10, Correct: 10\n",
      "[9.9999070e-01 3.7071015e-06 5.6608278e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 11, Correct: 11\n",
      "[9.9999750e-01 1.7317666e-06 7.1336802e-07]\n",
      "action:  0  -  0\n",
      "Attempt: 12, Correct: 12\n",
      "[9.9999487e-01 2.4902035e-06 2.5850247e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 13, Correct: 13\n",
      "[9.9999213e-01 1.1608288e-06 6.6732191e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 14, Correct: 14\n",
      "[9.9999976e-01 9.2059501e-08 1.6864777e-07]\n",
      "action:  0  -  0\n",
      "Attempt: 15, Correct: 15\n",
      "[9.9999881e-01 7.1836695e-07 4.3235303e-07]\n",
      "action:  0  -  0\n",
      "Attempt: 16, Correct: 16\n",
      "[9.9998915e-01 7.9452630e-06 2.9182561e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 17, Correct: 17\n",
      "[9.9998653e-01 1.0305847e-06 1.2429049e-05]\n",
      "action:  0  -  0\n",
      "Attempt: 18, Correct: 18\n",
      "[9.9999738e-01 1.0740412e-06 1.5384226e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 19, Correct: 19\n",
      "[9.9999893e-01 5.9200806e-07 4.3868988e-07]\n",
      "action:  0  -  0\n",
      "Attempt: 20, Correct: 20\n",
      "[9.9999475e-01 1.2905163e-06 3.9171650e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 21, Correct: 21\n",
      "[9.9998975e-01 1.1272526e-06 9.1675638e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 22, Correct: 22\n",
      "[9.9998224e-01 7.6804881e-06 1.0118877e-05]\n",
      "action:  0  -  0\n",
      "Attempt: 23, Correct: 23\n",
      "[9.9999857e-01 1.6997369e-07 1.3435304e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 24, Correct: 24\n",
      "[9.9999559e-01 1.7976243e-06 2.6227417e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 25, Correct: 25\n",
      "[9.9999988e-01 1.5231430e-08 1.4764028e-07]\n",
      "action:  0  -  0\n",
      "Attempt: 26, Correct: 26\n",
      "[9.9999750e-01 1.1404927e-06 1.2581328e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 27, Correct: 27\n",
      "[9.9998522e-01 1.9914237e-06 1.2698988e-05]\n",
      "action:  0  -  0\n",
      "Attempt: 28, Correct: 28\n",
      "[9.9999225e-01 1.3483276e-06 6.4587407e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 29, Correct: 29\n",
      "[9.9999964e-01 8.7980943e-08 1.9758971e-07]\n",
      "action:  0  -  0\n",
      "Attempt: 30, Correct: 30\n",
      "[9.9999321e-01 5.2108808e-06 1.5667133e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 31, Correct: 31\n",
      "[9.9999774e-01 6.6549364e-07 1.5810789e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 32, Correct: 32\n",
      "[9.9999976e-01 2.6878482e-07 3.6671912e-09]\n",
      "action:  0  -  0\n",
      "Attempt: 33, Correct: 33\n",
      "[9.9999666e-01 1.7878162e-06 1.5632294e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 34, Correct: 34\n",
      "[9.999995e-01 4.678922e-07 3.639858e-10]\n",
      "action:  0  -  0\n",
      "Attempt: 35, Correct: 35\n",
      "[9.9999642e-01 4.6476214e-07 3.0404260e-06]\n",
      "action:  0  -  0\n",
      "Attempt: 36, Correct: 36\n",
      "[7.3099673e-06 9.9998879e-01 3.8757239e-06]\n",
      "action:  1  -  1\n",
      "Attempt: 37, Correct: 37\n",
      "[1.4552504e-06 9.9999797e-01 6.3619581e-07]\n",
      "action:  1  -  1\n",
      "Attempt: 38, Correct: 38\n",
      "[2.8342447e-06 9.9999619e-01 9.2594917e-07]\n",
      "action:  1  -  1\n",
      "Attempt: 39, Correct: 39\n",
      "[7.8240674e-07 9.9999809e-01 1.0206454e-06]\n",
      "action:  1  -  1\n",
      "Attempt: 40, Correct: 40\n",
      "[7.2690732e-08 9.9999976e-01 1.0018939e-07]\n",
      "action:  1  -  1\n",
      "Attempt: 41, Correct: 41\n",
      "[3.4151162e-07 9.9999893e-01 6.9034564e-07]\n",
      "action:  1  -  1\n",
      "Attempt: 42, Correct: 42\n",
      "[1.522898e-06 9.999925e-01 5.923733e-06]\n",
      "action:  1  -  1\n",
      "Attempt: 43, Correct: 43\n",
      "[1.9079287e-06 9.9999654e-01 1.5676721e-06]\n",
      "action:  1  -  1\n",
      "Attempt: 44, Correct: 44\n",
      "[4.8650259e-07 9.9999857e-01 9.3937928e-07]\n",
      "action:  1  -  1\n",
      "Attempt: 45, Correct: 45\n",
      "[1.2729473e-07 9.9999964e-01 2.7522734e-07]\n",
      "action:  1  -  1\n",
      "Attempt: 46, Correct: 46\n",
      "[5.6696473e-07 9.9999917e-01 2.1937710e-07]\n",
      "action:  1  -  1\n",
      "Attempt: 47, Correct: 47\n",
      "[1.3173688e-08 1.0000000e+00 1.4928911e-08]\n",
      "action:  1  -  1\n",
      "Attempt: 48, Correct: 48\n",
      "[8.4180492e-08 9.9999964e-01 1.7967531e-07]\n",
      "action:  1  -  1\n",
      "Attempt: 49, Correct: 49\n",
      "[5.6153789e-07 9.9999917e-01 2.3477777e-07]\n",
      "action:  1  -  1\n",
      "Attempt: 50, Correct: 50\n",
      "[5.7442758e-08 9.9999893e-01 1.0636651e-06]\n",
      "action:  1  -  1\n",
      "Attempt: 51, Correct: 51\n",
      "[1.9301683e-06 9.9999642e-01 1.7269507e-06]\n",
      "action:  1  -  1\n",
      "Attempt: 52, Correct: 52\n",
      "[1.6793966e-07 9.9999976e-01 1.6791402e-07]\n",
      "action:  1  -  1\n",
      "Attempt: 53, Correct: 53\n",
      "[7.005636e-06 9.999864e-01 6.515315e-06]\n",
      "action:  1  -  1\n",
      "Attempt: 54, Correct: 54\n",
      "[4.7274079e-07 9.9999869e-01 8.0789033e-07]\n",
      "action:  1  -  1\n",
      "Attempt: 55, Correct: 55\n",
      "[4.7488274e-11 1.0000000e+00 1.1240237e-11]\n",
      "action:  1  -  1\n",
      "Attempt: 56, Correct: 56\n",
      "[2.8839972e-07 9.9999964e-01 6.0376735e-08]\n",
      "action:  1  -  1\n",
      "Attempt: 57, Correct: 57\n",
      "[5.7776890e-07 9.9999809e-01 1.3649125e-06]\n",
      "action:  1  -  1\n",
      "Attempt: 58, Correct: 58\n",
      "[1.2402803e-06 9.9998355e-01 1.5276681e-05]\n",
      "action:  1  -  1\n",
      "Attempt: 59, Correct: 59\n",
      "[3.0874236e-07 9.9999928e-01 3.8479052e-07]\n",
      "action:  1  -  1\n",
      "Attempt: 60, Correct: 60\n",
      "[4.9703954e-07 9.9999690e-01 2.6360226e-06]\n",
      "action:  1  -  1\n",
      "Attempt: 61, Correct: 61\n",
      "[3.4875203e-08 9.9999988e-01 6.6961888e-08]\n",
      "action:  1  -  1\n",
      "Attempt: 62, Correct: 62\n",
      "[7.6983114e-10 1.0000000e+00 7.7498308e-10]\n",
      "action:  1  -  1\n",
      "Attempt: 63, Correct: 63\n",
      "[4.2902935e-09 9.9999988e-01 1.4802205e-07]\n",
      "action:  1  -  1\n",
      "Attempt: 64, Correct: 64\n",
      "[1.5555595e-06 9.9999726e-01 1.1688799e-06]\n",
      "action:  1  -  1\n",
      "Attempt: 65, Correct: 65\n",
      "[1.7077267e-09 1.0000000e+00 1.7779340e-09]\n",
      "action:  1  -  1\n",
      "Attempt: 66, Correct: 66\n",
      "[7.2175645e-08 9.9999917e-01 7.1339707e-07]\n",
      "action:  1  -  1\n",
      "Attempt: 67, Correct: 67\n",
      "[5.0695957e-07 9.9991930e-01 8.0262747e-05]\n",
      "action:  1  -  1\n",
      "Attempt: 68, Correct: 68\n",
      "[2.5543852e-07 9.9999857e-01 1.2194313e-06]\n",
      "action:  1  -  1\n",
      "Attempt: 69, Correct: 69\n",
      "[6.549658e-06 9.999851e-01 8.388189e-06]\n",
      "action:  1  -  1\n",
      "Attempt: 70, Correct: 70\n",
      "[1.8354658e-07 9.9999917e-01 6.0866529e-07]\n",
      "action:  1  -  1\n",
      "Attempt: 71, Correct: 71\n",
      "[1.1122296e-06 9.9999881e-01 1.0639048e-07]\n",
      "action:  1  -  1\n",
      "Attempt: 72, Correct: 72\n",
      "[8.9505247e-06 6.3499242e-06 9.9998474e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 73, Correct: 73\n",
      "[1.10759665e-05 1.01988320e-07 9.99988794e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 74, Correct: 74\n",
      "[1.6390917e-08 3.8288439e-09 1.0000000e+00]\n",
      "action:  2  -  2\n",
      "Attempt: 75, Correct: 75\n",
      "[1.4202432e-05 5.0186458e-07 9.9998534e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 76, Correct: 76\n",
      "[1.6370629e-07 2.1574277e-08 9.9999976e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 77, Correct: 77\n",
      "[7.5757896e-05 9.4996094e-06 9.9991477e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 78, Correct: 78\n",
      "[6.6946500e-06 5.0896514e-08 9.9999321e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 79, Correct: 79\n",
      "[2.6774703e-08 7.1513419e-08 9.9999988e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 80, Correct: 80\n",
      "[2.1300170e-06 7.7931179e-07 9.9999714e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 81, Correct: 81\n",
      "[1.2957277e-07 1.1120388e-08 9.9999988e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 82, Correct: 82\n",
      "[5.7039290e-07 2.7468094e-08 9.9999940e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 83, Correct: 83\n",
      "[5.0370378e-05 1.7410018e-06 9.9994791e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 84, Correct: 84\n",
      "[3.5950814e-07 8.0197262e-09 9.9999964e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 85, Correct: 85\n",
      "[4.0305655e-05 1.5265015e-05 9.9994445e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 86, Correct: 86\n",
      "[1.10458395e-05 1.14559407e-06 9.99987841e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 87, Correct: 87\n",
      "[1.7138659e-07 8.4598959e-09 9.9999976e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 88, Correct: 88\n",
      "[4.5698762e-05 6.8726644e-07 9.9995363e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 89, Correct: 89\n",
      "[3.4598299e-05 4.0215778e-06 9.9996138e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 90, Correct: 90\n",
      "[3.7479488e-08 1.1490426e-08 1.0000000e+00]\n",
      "action:  2  -  2\n",
      "Attempt: 91, Correct: 91\n",
      "[5.2196492e-07 7.9401104e-08 9.9999940e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 92, Correct: 92\n",
      "[7.898497e-07 2.131352e-06 9.999970e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 93, Correct: 93\n",
      "[1.5879746e-08 2.5724635e-08 1.0000000e+00]\n",
      "action:  2  -  2\n",
      "Attempt: 94, Correct: 94\n",
      "[6.9229191e-06 1.2862636e-06 9.9999177e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 95, Correct: 95\n",
      "[4.0261807e-07 4.2015785e-08 9.9999952e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 96, Correct: 96\n",
      "[9.371939e-08 7.865231e-08 9.999999e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 97, Correct: 97\n",
      "[9.9434703e-07 1.3865365e-07 9.9999881e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 98, Correct: 98\n",
      "[9.3616492e-08 2.8995145e-10 9.9999988e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 99, Correct: 99\n",
      "[6.4387386e-06 7.1570332e-07 9.9999285e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 100, Correct: 100\n",
      "[4.379985e-06 4.774689e-08 9.999956e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 101, Correct: 101\n",
      "[5.1316188e-06 1.0060228e-06 9.9999392e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 102, Correct: 102\n",
      "[3.0240233e-07 1.7442484e-07 9.9999952e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 103, Correct: 103\n",
      "[1.7883529e-07 2.3843727e-08 9.9999976e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 104, Correct: 104\n",
      "[2.4203500e-06 1.5101948e-07 9.9999738e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 105, Correct: 105\n",
      "[6.8931079e-09 6.1067254e-08 9.9999988e-01]\n",
      "action:  2  -  2\n",
      "Attempt: 106, Correct: 106\n",
      "[5.6441827e-06 5.9631481e-07 9.9999380e-01]\n",
      "action:  2  -  2\n",
      "\n",
      "Validation done... 108 108\n",
      "Accuracy: 100.00%\n",
      "100.0 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def dqn_eval(dqn_agent,d):\n",
    "    attempts, correct = 0, 0\n",
    "    labels = d[1]\n",
    "    eenv = Plasticity(dataset=d, random=False)\n",
    "    thing = 1\n",
    "    y_pred = []\n",
    "    try:\n",
    "        \n",
    "        while True:\n",
    "            \n",
    "            if thing == 1:\n",
    "                obs = eenv.reset()\n",
    "                thing = 0\n",
    "            done = False\n",
    "            while not done:\n",
    "                # Reshape the observation to match the input shape of the model\n",
    "                obs_reshaped = np.reshape(obs, (1,) + obs.shape)\n",
    "                # Get Q-values from the model\n",
    "                q_values = dqn_agent.compute_q_values(obs_reshaped)\n",
    "                print(q_values)\n",
    "                # Select the action with the highest Q-value\n",
    "                action = np.argmax(q_values)\n",
    "                y_pred.append(action)\n",
    "                print('action: ', action, \" - \", labels[attempts])\n",
    "                # Take the step using the selected action\n",
    "                obs, rew, done, _ = eenv.step(action)\n",
    "\n",
    "                if done:\n",
    "                    attempts += 1\n",
    "                    if rew > 0:\n",
    "                        correct += 1\n",
    "                    print(f\"Attempt: {attempts}, Correct: {correct}\")\n",
    "\n",
    "            \n",
    "\n",
    "    except StopIteration:\n",
    "        print()\n",
    "        print('Validation done...',correct+2,attempts+2)\n",
    "        print('Accuracy: {:.2f}%'.format((float(correct+2) / (attempts+2)) * 100))\n",
    "    return (float(correct+2) / (attempts+2)), y_pred\n",
    "\n",
    "\n",
    "def dqn_eval2():\n",
    "     \n",
    "    n_splits = 10\n",
    "\n",
    "    \n",
    "    mean_rewards_per_fold = []\n",
    "    acc_per_fold = []\n",
    "    # Loop over each fold\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "    for train_index, test_index in skf.split(features_array,label_array):\n",
    "        xtr, xte = features_array[train_index],features_array[test_index]\n",
    "        ytr, yte = label_array[train_index], label_array[test_index]\n",
    "\n",
    "        train_env = Plasticity(dataset=(xtr,ytr),random=True)\n",
    "        test_env = Plasticity(dataset = (xte, yte),random=False)\n",
    "        dqn.fit(train_env,nb_steps=200,verbose=1)\n",
    "        scores = dqn.test(test_env, nb_episodes=1, visualize=False, verbose=0)\n",
    "        acc = dqn_eval(dqn,d=(xte, yte))\n",
    "        \n",
    "        mean_reward = np.mean(scores.history['episode_reward'])\n",
    "        mean_rewards_per_fold.append(mean_reward)\n",
    "        acc_per_fold.append(acc)\n",
    "   \n",
    "    overall_mean_reward = np.mean(mean_rewards_per_fold)\n",
    "    acc_avg = np.mean(acc_per_fold)\n",
    "    print(f\"Overall Mean Reward across all folds: {overall_mean_reward * 100} %\")\n",
    "    print(f\"Overall Mean Accuracy across all folds: {acc_avg * 100} %\")\n",
    "    print(mean_rewards_per_fold)\n",
    "dqn_eval2()\n",
    "print('***************************************************************************************')\n",
    "dqn_eval(dqn,d=(features_array,label_array))\n",
    "scores = dqn.test(Plasticity(dataset=(features_array,label_array),random=False), nb_episodes=15, visualize=False, verbose=0)\n",
    "print(np.mean(scores.history['episode_reward'])*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'mse', 'mean_q']\n",
      "100.0 %\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'RewardHistory' object has no attribute 'rewards'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/eeshan/Music/KernelModuleDefs/SystemIntegrityProtocols/5eee7de7454beed9d83660fb3a4535c1/3202b0f40c9b6d03df8679cc2d85fea0/85df3becdfcb4d7e35c74befeee54aa5/33507a4383e3645034645fb210bfebbe/ffc1b50d6da82d6fbbfaad7d8e06c271/a/NeuroAssist (1) copy.ipynb Cell 25\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Btbam-workstation/home/eeshan/Music/KernelModuleDefs/SystemIntegrityProtocols/5eee7de7454beed9d83660fb3a4535c1/3202b0f40c9b6d03df8679cc2d85fea0/85df3becdfcb4d7e35c74befeee54aa5/33507a4383e3645034645fb210bfebbe/ffc1b50d6da82d6fbbfaad7d8e06c271/a/NeuroAssist%20%281%29%20copy.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m plt\u001b[39m.\u001b[39mgrid(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Btbam-workstation/home/eeshan/Music/KernelModuleDefs/SystemIntegrityProtocols/5eee7de7454beed9d83660fb3a4535c1/3202b0f40c9b6d03df8679cc2d85fea0/85df3becdfcb4d7e35c74befeee54aa5/33507a4383e3645034645fb210bfebbe/ffc1b50d6da82d6fbbfaad7d8e06c271/a/NeuroAssist%20%281%29%20copy.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m---> <a href='vscode-notebook-cell://tunnel%2Btbam-workstation/home/eeshan/Music/KernelModuleDefs/SystemIntegrityProtocols/5eee7de7454beed9d83660fb3a4535c1/3202b0f40c9b6d03df8679cc2d85fea0/85df3becdfcb4d7e35c74befeee54aa5/33507a4383e3645034645fb210bfebbe/ffc1b50d6da82d6fbbfaad7d8e06c271/a/NeuroAssist%20%281%29%20copy.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(moving_average(reward_history\u001b[39m.\u001b[39;49mrewards, window_size\u001b[39m=\u001b[39m\u001b[39m70\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Btbam-workstation/home/eeshan/Music/KernelModuleDefs/SystemIntegrityProtocols/5eee7de7454beed9d83660fb3a4535c1/3202b0f40c9b6d03df8679cc2d85fea0/85df3becdfcb4d7e35c74befeee54aa5/33507a4383e3645034645fb210bfebbe/ffc1b50d6da82d6fbbfaad7d8e06c271/a/NeuroAssist%20%281%29%20copy.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mTraining Rewards per Episode\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Btbam-workstation/home/eeshan/Music/KernelModuleDefs/SystemIntegrityProtocols/5eee7de7454beed9d83660fb3a4535c1/3202b0f40c9b6d03df8679cc2d85fea0/85df3becdfcb4d7e35c74befeee54aa5/33507a4383e3645034645fb210bfebbe/ffc1b50d6da82d6fbbfaad7d8e06c271/a/NeuroAssist%20%281%29%20copy.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mEpisode\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RewardHistory' object has no attribute 'rewards'"
     ]
    }
   ],
   "source": [
    "scores = dqn.test(env=Plasticity(dataset=(features_array,label_array),random=False), nb_episodes=25, visualize=False, callbacks=[reward_history],verbose=0)\n",
    "print(np.mean(scores.history['episode_reward'])*100,'%')\n",
    "plt.plot(scores.history['episode_reward'])\n",
    "plt.title('Testing Rewards per Episode')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Cumulative Reward')\n",
    "plt.show()\n",
    "print(np.mean(scores.history['episode_reward'])*100,'%')\n",
    "print(label_array,label_array.shape)\n",
    "\n",
    "dqn_eval(dqn,d=(features_array,label_array))\n",
    "def moving_average(data, window_size):\n",
    "    return [np.mean(data[i:i+window_size]) for i in range(len(data) - window_size + 1)]\n",
    "losses = loss_history.losses\n",
    "losses2 = loss_history2.losses\n",
    "smoothed_losses = moving_average(losses, window_size=50)  \n",
    "print(smoothed_losses)\n",
    "plt.plot(smoothed_losses)\n",
    "plt.title('Smoothed Training Loss per Step')\n",
    "plt.xlabel('Step')\n",
    "plt.xlim(left=0)\n",
    "plt.ylabel('Smoothed Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "smoothed_losses2 = moving_average(losses2, window_size=70)  \n",
    "print(smoothed_losses2)\n",
    "plt.plot(smoothed_losses2)\n",
    "plt.title('Smoothed Training Loss per Step')\n",
    "plt.xlabel('Step')\n",
    "plt.xlim(left=0)\n",
    "plt.ylabel('Smoothed Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(moving_average(reward_history.rewards, window_size=70))\n",
    "plt.title('Training Rewards per Episode')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Cumulative Reward')\n",
    "plt.show()\n",
    "\n",
    "print(\"___________________________________________________________________________________________________________________________\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
