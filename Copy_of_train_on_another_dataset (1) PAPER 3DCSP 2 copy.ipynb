{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bpOrblegVkBG",
    "outputId": "6bfba428-25f7-42bf-ed8a-edae2a203c48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.64.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mne in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: decorator in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from mne) (5.1.1)\n",
      "Requirement already satisfied: jinja2 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from mne) (3.1.3)\n",
      "Requirement already satisfied: lazy-loader>=0.3 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from mne) (0.4)\n",
      "Requirement already satisfied: matplotlib>=3.6 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from mne) (3.9.2)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from mne) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from mne) (23.2)\n",
      "Requirement already satisfied: pooch>=1.5 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from mne) (1.8.2)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from mne) (1.13.0)\n",
      "Requirement already satisfied: tqdm in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from mne) (4.66.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from matplotlib>=3.6->mne) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from matplotlib>=3.6->mne) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from matplotlib>=3.6->mne) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from matplotlib>=3.6->mne) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from matplotlib>=3.6->mne) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from matplotlib>=3.6->mne) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from pooch>=1.5->mne) (4.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from pooch>=1.5->mne) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from jinja2->mne) (2.1.5)\n",
      "Requirement already satisfied: colorama in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from tqdm->mne) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from gym) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from gym) (3.1.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\dev\\webdevfolder\\realestateai\\.venv\\lib\\site-packages (from gym) (0.0.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jinja2 3.1.3 requires MarkupSafe>=2.0, but you have markupsafe 1.1.1 which is incompatible.\n",
      "werkzeug 3.0.2 requires MarkupSafe>=2.1.1, but you have markupsafe 1.1.1 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting markupsafe==1.1.1\n",
      "  Downloading MarkupSafe-1.1.1.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: markupsafe\n",
      "  Building wheel for markupsafe (setup.py): started\n",
      "  Building wheel for markupsafe (setup.py): finished with status 'done'\n",
      "  Created wheel for markupsafe: filename=MarkupSafe-1.1.1-cp312-cp312-win_amd64.whl size=19680 sha256=2eab5ffd512884bc9bb9376825849cc7c12b1865f78c517ddbacc12f8a6025b4\n",
      "  Stored in directory: c:\\users\\ncvn\\appdata\\local\\pip\\cache\\wheels\\ff\\6d\\06\\f08a8fbf292f9c43851e9d71174d98d1262f11ddaeb5dbe290\n",
      "Successfully built markupsafe\n",
      "Installing collected packages: markupsafe\n",
      "  Attempting uninstall: markupsafe\n",
      "    Found existing installation: MarkupSafe 2.1.5\n",
      "    Uninstalling MarkupSafe-2.1.5:\n",
      "      Successfully uninstalled MarkupSafe-2.1.5\n",
      "Successfully installed markupsafe-1.1.1\n",
      "TF VERSION 2.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install mne\n",
    "!pip install gym\n",
    "!pip install markupsafe==1.1.1\n",
    "import tensorflow as tf\n",
    "print('TF VERSION',tf.__version__)\n",
    "\n",
    "# !pip uninstall tensorflow\n",
    "# !pip uninstall tensorflow-gpu\n",
    "# !pip install tensorflow==2.15.0\n",
    "# !pip install tensorflow-gpu==2.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AI4DY3U_SpAD",
    "outputId": "8ef3baf3-e7cc-4d58-cb22-a0392124863e"
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "import gym\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "class NDStandardScaler(TransformerMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        self._scaler = StandardScaler(copy=True, **kwargs)\n",
    "        self._orig_shape = None\n",
    "\n",
    "    def fit(self, X, **kwargs):\n",
    "        X = np.array(X)\n",
    "        # Save the original shape to reshape the flattened X later\n",
    "        # back to its original shape\n",
    "        if len(X.shape) > 1:\n",
    "            self._orig_shape = X.shape[1:]\n",
    "        X = self._flatten(X)\n",
    "        self._scaler.fit(X, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, **kwargs):\n",
    "        X = np.array(X)\n",
    "        X = self._flatten(X)\n",
    "        X = self._scaler.transform(X, **kwargs)\n",
    "        X = self._reshape(X)\n",
    "        return X\n",
    "\n",
    "    def _flatten(self, X):\n",
    "        # Reshape X to <= 2 dimensions\n",
    "        if len(X.shape) > 2:\n",
    "            n_dims = np.prod(self._orig_shape)\n",
    "            X = X.reshape(-1, n_dims)\n",
    "        return X\n",
    "\n",
    "    def _reshape(self, X):\n",
    "        # Reshape X back to it's original shape\n",
    "        if len(X.shape) >= 2:\n",
    "            X = X.reshape(-1, *self._orig_shape)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "import scipy.signal\n",
    "from scipy import stats\n",
    "def mean(x):\n",
    "    return np.mean(x, axis=-1).reshape(-1, 1)\n",
    "\n",
    "def stddev(x):\n",
    "    return np.std(x, axis=-1).reshape(-1, 1)\n",
    "\n",
    "def peaktopeak(x):\n",
    "    return np.ptp(x, axis=-1).reshape(-1, 1)\n",
    "\n",
    "def variance(x):\n",
    "    return np.var(x, axis=-1).reshape(-1, 1)\n",
    "\n",
    "def mini(x):\n",
    "    return np.min(x, axis=-1).reshape(-1, 1)\n",
    "\n",
    "def maxi(x):\n",
    "    return np.max(x, axis=-1).reshape(-1, 1)\n",
    "\n",
    "def argmini(x):\n",
    "    return np.argmin(x, axis=-1).reshape(-1, 1)\n",
    "\n",
    "def argmaxi(x):\n",
    "    return np.argmax(x, axis=-1).reshape(-1, 1)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.mean(x**2, axis=-1)).reshape(-1, 1)\n",
    "\n",
    "def abs_diff_signal(x):\n",
    "    return np.sum(np.abs(np.diff(x, axis=-1)), axis=-1).reshape(-1, 1)\n",
    "\n",
    "def skewness(x):\n",
    "    return stats.skew(x, axis=-1).reshape(-1, 1)\n",
    "\n",
    "def kurtosis(x):\n",
    "    return stats.kurtosis(x, axis=-1).reshape(-1, 1)\n",
    "\n",
    "def concat_features(x):\n",
    "    features = np.concatenate(\n",
    "        (\n",
    "            peaktopeak(x),\n",
    "            rms(x),\n",
    "            abs_diff_signal(x),\n",
    "            skewness(x),\n",
    "            kurtosis(x),\n",
    "            variance(x),\n",
    "            mean(x),\n",
    "            stddev(x)\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    return features\n",
    "\n",
    "def apply_cwt(data, scales, wavelet_name='morl'):\n",
    "    \"\"\"\n",
    "    Apply Continuous Wavelet Transform (CWT) to EEG data.\n",
    "\n",
    "    :param data: EEG data in CSP space with shape (components, timepoints)\n",
    "    :param scales: Scales for CWT\n",
    "    :param wavelet_name: Name of the mother wavelet for CWT\n",
    "    :return: CWT coefficients\n",
    "    \"\"\"\n",
    "    cwt_coeffs = np.array([pywt.cwt(data[i, :], scales, wavelet_name)[0] for i in range(data.shape[0])])\n",
    "    return cwt_coeffs\n",
    "\n",
    "    \n",
    "def featuresarray_load(data_array):\n",
    "    features = []\n",
    "    fs = 500\n",
    "    for d in data_array:\n",
    "        \n",
    "       \n",
    "        alpha = mne.filter.filter_data(d, sfreq=fs, l_freq=8, h_freq=12,verbose=False)\n",
    "        beta = mne.filter.filter_data(d, sfreq=fs, l_freq=12, h_freq=30,verbose=False)\n",
    "        \n",
    "        alph_ftrs = concat_features(alpha)\n",
    "        beta_ftrs = concat_features(beta)\n",
    "        \n",
    "        #nperseg = 256\n",
    "        \n",
    "        \n",
    "        _,p=scipy.signal.welch(beta, fs=fs,average='median',nfft = data_array.shape[2]//2)\n",
    "        _,p2=scipy.signal.welch(alpha, fs=fs,average='median',nfft = data_array.shape[2]//2)\n",
    "        \n",
    "\n",
    "        res = np.mean([alph_ftrs,beta_ftrs],axis=0)\n",
    "        #print('p',p.shape,res.shape)\n",
    "        res = np.concatenate((res,p,p2),axis=1)\n",
    "        #print(res.shape)\n",
    "        features.append(res)\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 7, 1: 8, 2: 9, 3: 10}\n",
      "Extracting EDF parameters from c:\\DEV\\EEG\\a2\\data\\A02T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ncvn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 677168  =      0.000 ...  2708.672 secs...\n",
      "Fitting ICA to data using 22 channels (please be patient, this may take a while)\n",
      "Selecting by number: 22 components\n",
      "Fitting ICA took 10.1s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (22 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 22 PCA components\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from mne.decoding import CSP\n",
    "import mne\n",
    "from mne.decoding import CSP\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "event_ids = [7,8,9,10]  \n",
    "event_id_to_label = {}\n",
    "for i in range(len(event_ids)):\n",
    "    event_id_to_label[i] = event_ids[i]\n",
    "print(event_id_to_label)\n",
    "path = 'data/A02T.gdf'\n",
    "raw = mne.io.read_raw_gdf(path, eog=['EOG-left', 'EOG-central', 'EOG-right'], preload=True)\n",
    "raw.drop_channels(['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "ica = mne.preprocessing.ICA(n_components=len(raw.info['ch_names']), random_state=42, max_iter=1000)\n",
    "ica.fit(raw)\n",
    "ica.apply(raw)\n",
    "csp_filters = {} \n",
    "events = mne.events_from_annotations(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 1001 original time points ...\n",
      "1 bad epochs dropped\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "(287, 22, 1001) (287,)\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.00041 (2.2e-16 eps * 22 dim * 8.4e+10  max singular value)\n",
      "    Estimated rank (data): 22\n",
      "    data: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating class=0 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=1 covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.00041 (2.2e-16 eps * 22 dim * 8.4e+10  max singular value)\n",
      "    Estimated rank (data): 22\n",
      "    data: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating class=0 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=1 covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.00041 (2.2e-16 eps * 22 dim * 8.4e+10  max singular value)\n",
      "    Estimated rank (data): 22\n",
      "    data: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating class=0 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=1 covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.00041 (2.2e-16 eps * 22 dim * 8.4e+10  max singular value)\n",
      "    Estimated rank (data): 22\n",
      "    data: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating class=0 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=1 covariance using EMPIRICAL\n",
      "Done.\n",
      "CSP FILTERS DICT: {7: array([[[-0.09762406, -0.1484331 ,  0.58819388, ...,  0.06909049,\n",
      "          0.22591437, -0.09137934],\n",
      "        [ 0.45010764,  0.60750441, -0.05779538, ...,  1.1206118 ,\n",
      "          0.51954018,  0.52742743],\n",
      "        [ 1.28081822,  1.24705501,  1.03188375, ..., -0.69517442,\n",
      "         -0.91132559, -0.67843379],\n",
      "        [-0.93654998, -0.7045139 , -0.54426066, ..., -0.36817383,\n",
      "         -1.11010872,  0.08493283]],\n",
      "\n",
      "       [[-0.06506294, -0.21432524,  0.18154488, ..., -0.16920497,\n",
      "         -0.08171331, -0.03018277],\n",
      "        [ 0.03686324, -0.1709882 , -0.13978011, ..., -0.2186076 ,\n",
      "          0.13128694,  0.36520704],\n",
      "        [ 0.25716146, -0.27124733, -0.52719103, ..., -0.59509951,\n",
      "         -0.26809354, -0.16894248],\n",
      "        [-0.27928865,  0.14575274, -0.22247988, ...,  0.53316372,\n",
      "          0.10945493, -0.12381193]],\n",
      "\n",
      "       [[-0.22841419, -0.17477922,  0.03671834, ...,  0.16643478,\n",
      "         -0.21053514,  0.07140159],\n",
      "        [ 0.51867538,  0.27945842,  1.17712399, ..., -1.0133872 ,\n",
      "         -0.76476765, -0.15563474],\n",
      "        [ 1.23228944,  0.90974108,  0.29404576, ...,  1.11292554,\n",
      "          0.51419302,  0.63583984],\n",
      "        [ 0.05296619, -0.19796843,  0.39875418, ..., -0.51361661,\n",
      "         -0.51740809, -0.77016355]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.13958761,  0.12783728,  0.11959079, ..., -0.0180882 ,\n",
      "         -0.05403724, -0.11172783],\n",
      "        [ 0.25651732,  0.21039119,  0.22100804, ...,  0.6255162 ,\n",
      "          0.354656  ,  0.34795919],\n",
      "        [-0.5443669 ,  0.11562592, -0.0160889 , ..., -0.60018905,\n",
      "         -0.33300185, -1.00711716],\n",
      "        [-0.69983424, -0.96029167, -0.65442473, ...,  1.40740838,\n",
      "          0.31264971,  0.65698382]],\n",
      "\n",
      "       [[ 0.04436595,  0.20827237,  0.14933948, ..., -0.0033328 ,\n",
      "         -0.0912025 ,  0.01634012],\n",
      "        [ 0.53006825,  0.03893693, -0.16337315, ...,  0.24298157,\n",
      "         -0.1733849 , -0.6051003 ],\n",
      "        [ 1.95510202,  1.33687029,  1.19106448, ...,  1.45100876,\n",
      "          0.95076073,  0.96215077],\n",
      "        [-0.59766218, -0.10057729, -0.29354208, ...,  0.3798687 ,\n",
      "          0.48554807,  0.45140218]],\n",
      "\n",
      "       [[ 0.00931484,  0.05903513,  0.02606204, ..., -0.04440708,\n",
      "         -0.05422838, -0.02375152],\n",
      "        [-0.03327259, -0.60017362, -1.07270427, ..., -0.10288738,\n",
      "         -0.56293848, -0.21858217],\n",
      "        [ 0.1291337 ,  0.04679221, -0.38898463, ...,  0.91447368,\n",
      "          0.86169022,  0.86716623],\n",
      "        [-0.26238509, -0.44951689, -0.45072079, ..., -0.38808521,\n",
      "         -0.1248172 , -0.76721482]]]), 8: array([[[-1.33453176e-01, -1.98850675e-01,  8.72357654e-01, ...,\n",
      "          9.26315661e-02,  3.08442074e-01, -1.30122472e-01],\n",
      "        [-1.64255574e+00, -1.28300904e+00, -3.68886085e-01, ...,\n",
      "          2.49387835e-01, -4.09988087e-02,  6.64080325e-01],\n",
      "        [ 4.56606854e-01,  7.53268140e-01,  6.67174954e-01, ...,\n",
      "         -1.02409654e+00, -3.17228346e-01, -7.11771549e-01],\n",
      "        [ 7.05457420e-01,  4.44651597e-01,  5.08323807e-01, ...,\n",
      "         -2.70236172e-01,  3.82869704e-01,  1.76863678e-01]],\n",
      "\n",
      "       [[-9.32568653e-02, -3.13420338e-01,  2.65424309e-01, ...,\n",
      "         -2.42203275e-01, -1.18762733e-01, -4.21852907e-02],\n",
      "        [ 4.30275420e-01, -1.83186401e-01,  2.83798435e-01, ...,\n",
      "         -4.64864284e-02, -9.24566845e-01, -1.56441997e+00],\n",
      "        [-5.92967781e-01, -1.48557468e-01, -1.41865790e-01, ...,\n",
      "         -6.30979164e-01, -3.97186916e-01, -3.57672822e-01],\n",
      "        [-1.19309807e-01,  9.23197527e-02,  4.60053255e-02, ...,\n",
      "          1.17463988e+00,  1.17053253e+00,  1.04898530e+00]],\n",
      "\n",
      "       [[-3.32971841e-01, -2.52707142e-01,  5.11706487e-02, ...,\n",
      "          2.57613634e-01, -2.90161623e-01,  1.03552738e-01],\n",
      "        [ 8.93840987e-01,  4.69624642e-01, -2.53836591e-01, ...,\n",
      "         -1.62738933e-01, -1.10121412e-01, -2.95421677e-01],\n",
      "        [-3.71910557e-02,  4.10060736e-01, -7.55376386e-01, ...,\n",
      "         -1.01842890e+00,  4.08893410e-02, -7.71129174e-01],\n",
      "        [ 2.04685693e-01,  1.17818399e-01,  7.90034076e-01, ...,\n",
      "          3.83256687e-01,  4.39454202e-01,  8.17974618e-01]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 1.80976040e-01,  1.63245556e-01,  1.54079224e-01, ...,\n",
      "         -2.13589913e-02, -7.58247375e-02, -1.61597192e-01],\n",
      "        [-2.61329721e-01, -3.72394697e-01, -5.25310552e-01, ...,\n",
      "         -3.16476411e-01, -5.12465561e-01, -3.02959248e-01],\n",
      "        [ 5.09559570e-01, -1.08294810e-01, -2.76073549e-01, ...,\n",
      "         -1.65347622e+00, -6.20023540e-01, -1.38118203e+00],\n",
      "        [-1.16136426e+00, -1.42247833e+00, -1.29139301e+00, ...,\n",
      "          2.23864017e+00,  2.00641574e+00,  1.47800781e+00]],\n",
      "\n",
      "       [[ 7.24261618e-02,  3.10547307e-01,  2.20780916e-01, ...,\n",
      "          4.92356675e-03, -1.23547571e-01,  3.53792283e-02],\n",
      "        [-1.09693671e-01, -1.74553981e-01, -3.74736628e-03, ...,\n",
      "          1.01576175e+00,  1.03055222e+00,  1.06927942e+00],\n",
      "        [ 8.72530770e-01,  4.51602566e-01,  2.50397238e-01, ...,\n",
      "         -8.54526972e-01, -5.92522766e-01, -1.53148443e-01],\n",
      "        [-1.30772438e+00, -1.59830308e+00, -1.42216578e+00, ...,\n",
      "         -2.74920962e-02,  4.47302556e-01,  2.68900945e-01]],\n",
      "\n",
      "       [[ 7.16670422e-03,  7.97639315e-02,  3.29546941e-02, ...,\n",
      "         -6.05313078e-02, -7.89022530e-02, -2.36568575e-02],\n",
      "        [-8.41638550e-01, -5.67221750e-01, -2.44581262e-01, ...,\n",
      "         -4.94597277e-01, -5.67837290e-01, -8.99353570e-01],\n",
      "        [ 4.09900053e-02, -7.58649665e-03,  2.31768966e-01, ...,\n",
      "         -5.72216495e-01, -1.72788022e-01,  2.07125292e-01],\n",
      "        [-3.58605185e-01, -6.01601781e-01, -6.86490936e-01, ...,\n",
      "         -9.62099778e-02,  4.76025871e-01, -3.45584235e-04]]]), 9: array([[[ 0.6310935 ,  0.71841483,  0.44905712, ...,  1.05382486,\n",
      "          0.78696345,  0.64199219],\n",
      "        [ 0.73056037,  0.77060599,  1.32605308, ...,  0.55677295,\n",
      "          0.12441191,  0.83127515],\n",
      "        [-0.11743408, -0.17096697,  0.7801567 , ...,  0.16569872,\n",
      "          0.34094323, -0.06293153],\n",
      "        [-0.59503053,  0.00387285, -0.19867942, ..., -0.24601452,\n",
      "          0.11252764,  0.61106317]],\n",
      "\n",
      "       [[-0.12270068, -0.24961477, -0.11305009, ..., -0.11308515,\n",
      "          0.21636759,  0.43464576],\n",
      "        [ 0.28700234, -0.07690948,  0.63276814, ...,  1.12966399,\n",
      "          1.17980427,  1.45786715],\n",
      "        [-0.02695505, -0.25442857,  0.30615326, ..., -0.18061617,\n",
      "         -0.06280179,  0.01079947],\n",
      "        [ 0.190558  ,  0.57174143,  0.82253529, ...,  0.09440202,\n",
      "          0.27909693,  0.24098032]],\n",
      "\n",
      "       [[ 0.43776212,  0.20920559,  0.92298989, ..., -0.53494253,\n",
      "         -0.52527322,  0.10650597],\n",
      "        [ 0.06589273,  0.58038297,  0.80199535, ...,  2.16829165,\n",
      "          0.88210995,  0.74352858],\n",
      "        [-0.26711253, -0.17298284,  0.06906341, ...,  0.30055107,\n",
      "         -0.24076052,  0.11438946],\n",
      "        [-0.51340982, -0.38109782,  0.04225118, ...,  0.53181452,\n",
      "          1.12400637,  0.38698323]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.45184243,  0.50185173,  0.42454617, ...,  0.11957862,\n",
      "         -0.00610562,  0.06233342],\n",
      "        [ 0.19064203,  0.67127675,  1.08486429, ...,  0.02990727,\n",
      "         -0.60465807,  0.64713984],\n",
      "        [ 0.24523819,  0.26858824,  0.26992029, ..., -0.11240442,\n",
      "         -0.15403429, -0.14174681],\n",
      "        [-1.23261716, -1.45908757, -1.45388966, ...,  0.52181054,\n",
      "          0.51935833,  0.5217562 ]],\n",
      "\n",
      "       [[ 0.61980726,  0.12841951, -0.07485492, ..., -0.10608287,\n",
      "         -0.45245068, -0.7458119 ],\n",
      "        [-0.33924801,  0.48003058,  0.27818894, ...,  0.58650348,\n",
      "          0.92378631,  0.71959537],\n",
      "        [ 0.04509011,  0.28894952,  0.21982259, ...,  0.0460676 ,\n",
      "         -0.04590645,  0.07164246],\n",
      "        [ 0.44771509,  0.55162881,  0.48332692, ...,  0.22099887,\n",
      "         -0.0169978 ,  0.47806781]],\n",
      "\n",
      "       [[-0.2089306 , -0.62963072, -1.0288974 , ..., -0.22010126,\n",
      "         -0.73026321, -0.14877912],\n",
      "        [-0.32732672, -0.06676037,  0.3516548 , ..., -0.23112768,\n",
      "         -0.44691671,  0.52202493],\n",
      "        [ 0.0179068 ,  0.10656318,  0.1041972 , ..., -0.08031364,\n",
      "         -0.11210193, -0.0329746 ],\n",
      "        [ 0.45861562,  0.59776316,  0.81809689, ..., -0.42849973,\n",
      "         -0.62370386, -0.32639145]]]), 10: array([[[-1.48874748, -1.47077864, -0.78515159, ..., -0.23620775,\n",
      "         -0.51578357,  0.07117211],\n",
      "        [-0.15682652, -0.22496977,  0.71561213, ..., -0.02752819,\n",
      "          0.24136386, -0.20040877],\n",
      "        [ 0.51202736,  0.14839824, -0.30929241, ...,  1.40543726,\n",
      "          0.79689403,  0.89753107],\n",
      "        [-0.41387814, -0.39228579, -0.08140628, ...,  0.75361758,\n",
      "          0.67212539,  1.06332294]],\n",
      "\n",
      "       [[ 0.60710587,  0.12788667,  0.29362642, ...,  0.14688626,\n",
      "         -0.56211084, -1.08430839],\n",
      "        [-0.17563455, -0.24399906,  0.16759627, ..., -0.17852774,\n",
      "         -0.03739892,  0.02236888],\n",
      "        [ 0.43620432, -0.42790014,  0.19191031, ..., -0.28108389,\n",
      "         -0.34720187, -0.20154852],\n",
      "        [ 0.41747447,  0.00718293,  0.56638413, ...,  0.10770696,\n",
      "         -0.54931421, -0.7676323 ]],\n",
      "\n",
      "       [[ 0.23702357,  0.00365421, -0.59743849, ...,  0.76661073,\n",
      "          0.38359674,  0.17902348],\n",
      "        [-0.41114746, -0.30282246, -0.03769925, ...,  0.13250872,\n",
      "         -0.28990349,  0.05202274],\n",
      "        [ 0.85706691,  0.49786207,  0.96999985, ...,  0.36557568,\n",
      "         -0.22687265,  0.45752767],\n",
      "        [ 0.39232154,  0.03375247,  0.09119263, ..., -0.4103215 ,\n",
      "         -0.28636245, -0.41583106]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.49663135, -0.33096489, -0.29051249, ...,  0.18746609,\n",
      "         -0.10984318,  0.14786984],\n",
      "        [ 0.19384912,  0.13629008,  0.10795962, ...,  0.01124332,\n",
      "         -0.04227125, -0.13682233],\n",
      "        [ 0.43662467,  0.82872377,  0.99599942, ...,  0.05548652,\n",
      "          0.254837  ,  0.36212471],\n",
      "        [-0.03439776, -0.24318037, -0.38649564, ..., -0.26991075,\n",
      "         -0.17737164,  0.17664078]],\n",
      "\n",
      "       [[-0.46192652, -0.05300277,  0.22092342, ...,  1.03703912,\n",
      "          1.19420729,  1.27145431],\n",
      "        [-0.00927324,  0.20842862,  0.13660899, ..., -0.1316251 ,\n",
      "         -0.22484826, -0.07561305],\n",
      "        [ 0.57165449,  0.48762507,  0.48420193, ...,  0.39151232,\n",
      "          0.26817168,  0.12469035],\n",
      "        [-1.28043008, -1.14476729, -0.91220717, ..., -0.44635585,\n",
      "          0.00534989, -0.00965412]],\n",
      "\n",
      "       [[-0.12525608,  0.36207858,  0.70896463, ...,  0.14037937,\n",
      "          0.34693889, -0.37731414],\n",
      "        [-0.00331759,  0.04556255,  0.03761364, ..., -0.07834622,\n",
      "         -0.01005269, -0.05197042],\n",
      "        [ 0.57766876,  0.56386766, -0.03362776, ...,  0.06548358,\n",
      "         -0.7126679 ,  0.09243286],\n",
      "        [-0.75383623, -0.62579688, -0.44999088, ..., -0.65538936,\n",
      "         -1.12467783, -0.92793306]]])}\n",
      "(287, 4, 1001)\n",
      "(287, 4, 1001)\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]]\n",
      "[0 1 1 0 1 0 1 2 1 3 0 2 1 0 3 3 3 3 3 0 2 1 0 0 2 3 0 2 2 2 0 1 0 1 1 0 1\n",
      " 2 1 2 2 3 2 2 3 3 3 3 3 2 1 0 0 1 2 3 1 2 0 0 0 3 1 1 0 0 2 0 1 3 3 2 0 3\n",
      " 3 1 3 3 1 0 1 2 2 2 3 2 0 3 1 2 1 2 3 1 2 0 0 0 3 1 0 2 0 2 1 3 0 2 2 0 2\n",
      " 1 3 3 3 2 0 3 1 3 1 0 2 1 0 2 2 0 2 3 3 1 0 1 3 1 3 2 1 1 1 2 3 0 1 3 0 2\n",
      " 2 3 0 0 2 1 3 3 3 1 0 2 1 3 0 3 2 1 3 3 0 1 1 2 3 1 0 0 3 1 0 2 1 1 2 0 3\n",
      " 2 2 2 2 0 1 0 1 0 0 2 2 1 2 3 0 3 0 0 1 3 2 1 3 2 3 2 3 1 1 3 0 1 1 1 2 3\n",
      " 0 3 0 2 0 3 0 2 0 1 2 2 3 0 1 3 1 2 2 0 3 1 3 0 0 2 2 1 3 1 1 0 1 3 3 1 1\n",
      " 1 1 3 3 2 3 0 1 2 1 0 3 0 3 0 0 0 0 2 2 3 1 2 2 2 3 2 0]\n",
      "72 72 71 72\n",
      "features shape:  (287, 4, 1001) (287,)\n",
      "features shape:  (287, 4, 510) (287,)\n",
      "Epoch 1/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 264ms/step - accuracy: 0.3193 - loss: 39.1809 - val_accuracy: 0.2800 - val_loss: 35.7323\n",
      "Epoch 2/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 186ms/step - accuracy: 0.4390 - loss: 34.8656 - val_accuracy: 0.2800 - val_loss: 32.2457\n",
      "Epoch 3/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 208ms/step - accuracy: 0.6017 - loss: 31.0095 - val_accuracy: 0.2800 - val_loss: 29.0955\n",
      "Epoch 4/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 196ms/step - accuracy: 0.6265 - loss: 27.8457 - val_accuracy: 0.0800 - val_loss: 26.2584\n",
      "Epoch 5/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 201ms/step - accuracy: 0.6854 - loss: 24.9632 - val_accuracy: 0.0800 - val_loss: 23.7296\n",
      "Epoch 6/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 182ms/step - accuracy: 0.7759 - loss: 22.2331 - val_accuracy: 0.0800 - val_loss: 21.4614\n",
      "Epoch 7/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 194ms/step - accuracy: 0.7979 - loss: 19.9774 - val_accuracy: 0.0800 - val_loss: 19.4695\n",
      "Epoch 8/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 205ms/step - accuracy: 0.8485 - loss: 17.8764 - val_accuracy: 0.0800 - val_loss: 17.7301\n",
      "Epoch 9/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 207ms/step - accuracy: 0.8434 - loss: 16.1285 - val_accuracy: 0.0800 - val_loss: 16.2126\n",
      "Epoch 10/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step - accuracy: 0.8497 - loss: 14.5475 - val_accuracy: 0.0800 - val_loss: 14.8772\n",
      "Epoch 11/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - accuracy: 0.8505 - loss: 13.1811 - val_accuracy: 0.0800 - val_loss: 13.7305\n",
      "Epoch 12/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 0.8667 - loss: 11.9970 - val_accuracy: 0.0800 - val_loss: 12.7623\n",
      "Epoch 13/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 196ms/step - accuracy: 0.9172 - loss: 10.9024 - val_accuracy: 0.0800 - val_loss: 11.8233\n",
      "Epoch 14/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 190ms/step - accuracy: 0.8973 - loss: 9.9858 - val_accuracy: 0.2400 - val_loss: 10.9392\n",
      "Epoch 15/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 195ms/step - accuracy: 0.9451 - loss: 9.0548 - val_accuracy: 0.2800 - val_loss: 10.1054\n",
      "Epoch 16/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 190ms/step - accuracy: 0.9227 - loss: 8.3608 - val_accuracy: 0.2800 - val_loss: 9.4391\n",
      "Epoch 17/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 188ms/step - accuracy: 0.9616 - loss: 7.5905 - val_accuracy: 0.1600 - val_loss: 8.8347\n",
      "Epoch 18/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step - accuracy: 0.9649 - loss: 6.9739 - val_accuracy: 0.2400 - val_loss: 8.2977\n",
      "Epoch 19/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 194ms/step - accuracy: 0.9721 - loss: 6.3623 - val_accuracy: 0.2800 - val_loss: 7.7230\n",
      "Epoch 20/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 176ms/step - accuracy: 0.9581 - loss: 5.8551 - val_accuracy: 0.2400 - val_loss: 7.3776\n",
      "Epoch 21/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 195ms/step - accuracy: 0.9848 - loss: 5.3407 - val_accuracy: 0.2800 - val_loss: 6.9708\n",
      "Epoch 22/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 238ms/step - accuracy: 0.9894 - loss: 4.8704 - val_accuracy: 0.2800 - val_loss: 6.3904\n",
      "Epoch 23/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 194ms/step - accuracy: 0.9781 - loss: 4.4699 - val_accuracy: 0.2800 - val_loss: 5.9565\n",
      "Epoch 24/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step - accuracy: 0.9633 - loss: 4.0733 - val_accuracy: 0.2800 - val_loss: 5.6340\n",
      "Epoch 25/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 210ms/step - accuracy: 0.9902 - loss: 3.6511 - val_accuracy: 0.2800 - val_loss: 5.2784\n",
      "Epoch 26/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 199ms/step - accuracy: 0.9939 - loss: 3.3055 - val_accuracy: 0.2800 - val_loss: 5.0132\n",
      "Epoch 27/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 215ms/step - accuracy: 0.9784 - loss: 2.9975 - val_accuracy: 0.2800 - val_loss: 4.9656\n",
      "Epoch 28/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 195ms/step - accuracy: 0.9715 - loss: 2.7160 - val_accuracy: 0.2800 - val_loss: 4.5423\n",
      "Epoch 29/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 203ms/step - accuracy: 0.9982 - loss: 2.4163 - val_accuracy: 0.2800 - val_loss: 4.3767\n",
      "Epoch 30/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 198ms/step - accuracy: 0.9833 - loss: 2.1930 - val_accuracy: 0.2800 - val_loss: 4.1948\n",
      "Epoch 31/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - accuracy: 0.9917 - loss: 1.9376 - val_accuracy: 0.2800 - val_loss: 3.6782\n",
      "Epoch 32/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 198ms/step - accuracy: 0.9848 - loss: 1.7545 - val_accuracy: 0.2800 - val_loss: 3.9146\n",
      "Epoch 33/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 203ms/step - accuracy: 0.9862 - loss: 1.5757 - val_accuracy: 0.2800 - val_loss: 3.5240\n",
      "Epoch 34/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 197ms/step - accuracy: 0.9891 - loss: 1.4058 - val_accuracy: 0.2800 - val_loss: 3.7824\n",
      "Epoch 35/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - accuracy: 0.9956 - loss: 1.2510 - val_accuracy: 0.2800 - val_loss: 3.3408\n",
      "Epoch 36/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - accuracy: 0.9917 - loss: 1.1501 - val_accuracy: 0.2800 - val_loss: 2.5164\n",
      "Epoch 37/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - accuracy: 0.9870 - loss: 1.0892 - val_accuracy: 0.2800 - val_loss: 2.8280\n",
      "Epoch 38/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step - accuracy: 0.9817 - loss: 1.0370 - val_accuracy: 0.2800 - val_loss: 2.5908\n",
      "Epoch 39/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 188ms/step - accuracy: 0.9951 - loss: 0.9577 - val_accuracy: 0.2800 - val_loss: 2.4640\n",
      "Epoch 40/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 233ms/step - accuracy: 0.9982 - loss: 0.8805 - val_accuracy: 0.2800 - val_loss: 1.8577\n",
      "Epoch 41/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 0.7800 - val_accuracy: 0.7200 - val_loss: 1.6579\n",
      "Epoch 42/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 196ms/step - accuracy: 0.9681 - loss: 0.7741 - val_accuracy: 0.3200 - val_loss: 1.9408\n",
      "Epoch 43/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 188ms/step - accuracy: 0.9820 - loss: 0.7522 - val_accuracy: 0.3200 - val_loss: 2.7669\n",
      "Epoch 44/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 188ms/step - accuracy: 0.9865 - loss: 0.7423 - val_accuracy: 0.2800 - val_loss: 3.2043\n",
      "Epoch 45/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 180ms/step - accuracy: 0.9875 - loss: 0.7282 - val_accuracy: 0.2800 - val_loss: 2.8396\n",
      "Epoch 46/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 195ms/step - accuracy: 0.9624 - loss: 0.6993 - val_accuracy: 0.3200 - val_loss: 2.4910\n",
      "Epoch 47/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 194ms/step - accuracy: 0.9673 - loss: 0.7528 - val_accuracy: 0.2800 - val_loss: 1.9597\n",
      "Epoch 48/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step - accuracy: 0.9885 - loss: 0.7882 - val_accuracy: 0.4800 - val_loss: 1.8735\n",
      "Epoch 49/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step - accuracy: 0.9736 - loss: 0.8424 - val_accuracy: 0.7200 - val_loss: 1.5970\n",
      "Epoch 50/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 198ms/step - accuracy: 0.9823 - loss: 0.8007 - val_accuracy: 0.2800 - val_loss: 1.7726\n",
      "Epoch 51/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 205ms/step - accuracy: 0.9964 - loss: 0.7253 - val_accuracy: 0.2800 - val_loss: 1.9622\n",
      "Epoch 52/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 196ms/step - accuracy: 0.9542 - loss: 0.7306 - val_accuracy: 0.1600 - val_loss: 1.8579\n",
      "Epoch 53/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 243ms/step - accuracy: 0.9903 - loss: 0.6267 - val_accuracy: 0.6400 - val_loss: 1.4296\n",
      "Epoch 54/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step - accuracy: 0.9933 - loss: 0.5961 - val_accuracy: 0.4000 - val_loss: 1.7321\n",
      "Epoch 55/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - accuracy: 0.9796 - loss: 0.5987 - val_accuracy: 0.6000 - val_loss: 1.4462\n",
      "Epoch 56/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step - accuracy: 0.9857 - loss: 0.5762 - val_accuracy: 0.7200 - val_loss: 1.2646\n",
      "Epoch 57/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 194ms/step - accuracy: 0.9971 - loss: 0.5749 - val_accuracy: 0.4000 - val_loss: 1.3748\n",
      "Epoch 58/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step - accuracy: 0.9844 - loss: 0.5770 - val_accuracy: 0.4800 - val_loss: 1.4664\n",
      "Epoch 59/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 205ms/step - accuracy: 0.9804 - loss: 0.6196 - val_accuracy: 0.4000 - val_loss: 1.9464\n",
      "Epoch 60/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - accuracy: 0.9880 - loss: 0.6529 - val_accuracy: 0.4000 - val_loss: 2.0341\n",
      "Epoch 61/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 195ms/step - accuracy: 0.9963 - loss: 0.6427 - val_accuracy: 0.4800 - val_loss: 1.8597\n",
      "Epoch 62/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 193ms/step - accuracy: 0.9893 - loss: 0.5961 - val_accuracy: 0.8000 - val_loss: 1.1126\n",
      "Epoch 63/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step - accuracy: 0.9989 - loss: 0.5337 - val_accuracy: 0.8400 - val_loss: 0.9326\n",
      "Epoch 64/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - accuracy: 0.9964 - loss: 0.4534 - val_accuracy: 0.8400 - val_loss: 0.8431\n",
      "Epoch 65/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 0.9964 - loss: 0.4074 - val_accuracy: 0.7600 - val_loss: 1.0194\n",
      "Epoch 66/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 198ms/step - accuracy: 0.9776 - loss: 0.4332 - val_accuracy: 0.9200 - val_loss: 0.7521\n",
      "Epoch 67/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 206ms/step - accuracy: 0.9645 - loss: 0.5675 - val_accuracy: 0.6000 - val_loss: 1.2547\n",
      "Epoch 68/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 194ms/step - accuracy: 0.9963 - loss: 0.5727 - val_accuracy: 0.6400 - val_loss: 1.1919\n",
      "Epoch 69/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 200ms/step - accuracy: 1.0000 - loss: 0.5671 - val_accuracy: 0.8000 - val_loss: 1.0007\n",
      "Epoch 70/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 197ms/step - accuracy: 1.0000 - loss: 0.5359 - val_accuracy: 0.8800 - val_loss: 0.7578\n",
      "Epoch 71/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 202ms/step - accuracy: 0.9881 - loss: 0.4666 - val_accuracy: 0.9600 - val_loss: 0.6437\n",
      "Epoch 72/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - accuracy: 0.9964 - loss: 0.4084 - val_accuracy: 0.9200 - val_loss: 0.7649\n",
      "Epoch 73/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 203ms/step - accuracy: 0.9977 - loss: 0.4161 - val_accuracy: 0.8400 - val_loss: 0.8500\n",
      "Epoch 74/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - accuracy: 0.9752 - loss: 0.5205 - val_accuracy: 0.8800 - val_loss: 0.9019\n",
      "Epoch 75/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 198ms/step - accuracy: 0.9932 - loss: 0.6097 - val_accuracy: 0.9200 - val_loss: 0.8069\n",
      "Epoch 76/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - accuracy: 0.9820 - loss: 0.6627 - val_accuracy: 0.9600 - val_loss: 0.6987\n",
      "Epoch 77/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step - accuracy: 1.0000 - loss: 0.6218 - val_accuracy: 1.0000 - val_loss: 0.6551\n",
      "Epoch 78/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 206ms/step - accuracy: 0.9951 - loss: 0.5648 - val_accuracy: 0.9600 - val_loss: 0.6499\n",
      "Epoch 79/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 189ms/step - accuracy: 0.9974 - loss: 0.4937 - val_accuracy: 0.9600 - val_loss: 0.5347\n",
      "Epoch 80/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 186ms/step - accuracy: 0.9916 - loss: 0.4524 - val_accuracy: 1.0000 - val_loss: 0.4669\n",
      "Epoch 81/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 198ms/step - accuracy: 0.9852 - loss: 0.4689 - val_accuracy: 1.0000 - val_loss: 0.5027\n",
      "Epoch 82/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 189ms/step - accuracy: 0.9909 - loss: 0.4768 - val_accuracy: 1.0000 - val_loss: 0.4992\n",
      "Epoch 83/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step - accuracy: 1.0000 - loss: 0.4797 - val_accuracy: 1.0000 - val_loss: 0.5392\n",
      "Epoch 84/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 188ms/step - accuracy: 0.9893 - loss: 0.5114 - val_accuracy: 0.9200 - val_loss: 0.5859\n",
      "Epoch 85/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 190ms/step - accuracy: 0.9951 - loss: 0.4756 - val_accuracy: 0.9200 - val_loss: 0.6167\n",
      "Epoch 86/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step - accuracy: 1.0000 - loss: 0.4441 - val_accuracy: 1.0000 - val_loss: 0.4805\n",
      "Epoch 87/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 0.9974 - loss: 0.3955 - val_accuracy: 1.0000 - val_loss: 0.4081\n",
      "Epoch 88/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step - accuracy: 0.9989 - loss: 0.3499 - val_accuracy: 0.9200 - val_loss: 0.4409\n",
      "Epoch 89/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 0.3429 - val_accuracy: 0.9200 - val_loss: 0.5640\n",
      "Epoch 90/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step - accuracy: 0.9932 - loss: 0.3681 - val_accuracy: 0.9600 - val_loss: 0.4338\n",
      "Epoch 91/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 188ms/step - accuracy: 0.9989 - loss: 0.3491 - val_accuracy: 1.0000 - val_loss: 0.3887\n",
      "Epoch 92/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 245ms/step - accuracy: 0.9974 - loss: 0.3488 - val_accuracy: 0.9200 - val_loss: 0.4863\n",
      "Epoch 93/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 201ms/step - accuracy: 0.9898 - loss: 0.4051 - val_accuracy: 0.9600 - val_loss: 0.5772\n",
      "Epoch 94/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 196ms/step - accuracy: 0.9866 - loss: 0.4257 - val_accuracy: 0.9600 - val_loss: 0.5229\n",
      "Epoch 95/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 198ms/step - accuracy: 0.9896 - loss: 0.4558 - val_accuracy: 0.9600 - val_loss: 0.5644\n",
      "Epoch 96/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - accuracy: 0.9932 - loss: 0.4755 - val_accuracy: 0.9600 - val_loss: 0.4898\n",
      "Epoch 97/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 246ms/step - accuracy: 1.0000 - loss: 0.4351 - val_accuracy: 1.0000 - val_loss: 0.4028\n",
      "Epoch 98/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step - accuracy: 1.0000 - loss: 0.3769 - val_accuracy: 1.0000 - val_loss: 0.3375\n",
      "Epoch 99/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 0.3058 - val_accuracy: 1.0000 - val_loss: 0.2685\n",
      "Epoch 100/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 1.0000 - loss: 0.2465 - val_accuracy: 1.0000 - val_loss: 0.2462\n",
      "Epoch 101/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 189ms/step - accuracy: 0.9826 - loss: 0.2756 - val_accuracy: 1.0000 - val_loss: 0.3793\n",
      "Epoch 102/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 197ms/step - accuracy: 0.9673 - loss: 0.4346 - val_accuracy: 1.0000 - val_loss: 0.5320\n",
      "Epoch 103/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step - accuracy: 0.9928 - loss: 0.5853 - val_accuracy: 0.9600 - val_loss: 0.7732\n",
      "Epoch 104/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - accuracy: 0.9668 - loss: 0.7612 - val_accuracy: 0.8800 - val_loss: 1.2871\n",
      "Epoch 105/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step - accuracy: 0.9948 - loss: 0.7853 - val_accuracy: 0.9600 - val_loss: 0.8508\n",
      "Epoch 106/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - accuracy: 0.9932 - loss: 0.7680 - val_accuracy: 0.9600 - val_loss: 0.7228\n",
      "Epoch 107/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 189ms/step - accuracy: 0.9989 - loss: 0.6806 - val_accuracy: 0.9600 - val_loss: 0.6574\n",
      "Epoch 108/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 181ms/step - accuracy: 0.9964 - loss: 0.5819 - val_accuracy: 0.8800 - val_loss: 0.6705\n",
      "Epoch 109/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 1.0000 - loss: 0.4828 - val_accuracy: 0.8800 - val_loss: 0.7693\n",
      "Epoch 110/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 180ms/step - accuracy: 0.9867 - loss: 0.4297 - val_accuracy: 0.8800 - val_loss: 0.7486\n",
      "Epoch 111/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 194ms/step - accuracy: 0.9964 - loss: 0.3671 - val_accuracy: 0.8800 - val_loss: 0.6697\n",
      "Epoch 112/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 194ms/step - accuracy: 0.9786 - loss: 0.4252 - val_accuracy: 0.9200 - val_loss: 0.7973\n",
      "Epoch 113/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 179ms/step - accuracy: 1.0000 - loss: 0.4008 - val_accuracy: 0.9600 - val_loss: 0.6672\n",
      "Epoch 114/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 178ms/step - accuracy: 1.0000 - loss: 0.3884 - val_accuracy: 0.9600 - val_loss: 0.4874\n",
      "Epoch 115/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 186ms/step - accuracy: 1.0000 - loss: 0.3385 - val_accuracy: 0.9600 - val_loss: 0.4266\n",
      "Epoch 116/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 182ms/step - accuracy: 0.9867 - loss: 0.3191 - val_accuracy: 0.9600 - val_loss: 0.5164\n",
      "Epoch 117/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 180ms/step - accuracy: 0.9982 - loss: 0.3290 - val_accuracy: 0.9600 - val_loss: 0.3990\n",
      "Epoch 118/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 1.0000 - loss: 0.3377 - val_accuracy: 1.0000 - val_loss: 0.3583\n",
      "Epoch 119/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - accuracy: 0.9929 - loss: 0.3388 - val_accuracy: 1.0000 - val_loss: 0.3483\n",
      "Epoch 120/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 175ms/step - accuracy: 0.9908 - loss: 0.3545 - val_accuracy: 0.9600 - val_loss: 0.4037\n",
      "Epoch 121/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step - accuracy: 1.0000 - loss: 0.3620 - val_accuracy: 0.9600 - val_loss: 0.5478\n",
      "Epoch 122/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 0.9844 - loss: 0.4004 - val_accuracy: 0.9600 - val_loss: 0.4654\n",
      "Epoch 123/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - accuracy: 0.9964 - loss: 0.3827 - val_accuracy: 1.0000 - val_loss: 0.3912\n",
      "Epoch 124/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - accuracy: 0.9951 - loss: 0.3945 - val_accuracy: 1.0000 - val_loss: 0.3640\n",
      "Epoch 125/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step - accuracy: 0.9932 - loss: 0.3619 - val_accuracy: 1.0000 - val_loss: 0.3295\n",
      "Epoch 126/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 180ms/step - accuracy: 0.9916 - loss: 0.3391 - val_accuracy: 1.0000 - val_loss: 0.3192\n",
      "Epoch 127/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 180ms/step - accuracy: 0.9974 - loss: 0.3333 - val_accuracy: 1.0000 - val_loss: 0.3390\n",
      "Epoch 128/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 196ms/step - accuracy: 0.9932 - loss: 0.3699 - val_accuracy: 1.0000 - val_loss: 0.3662\n",
      "Epoch 129/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - accuracy: 1.0000 - loss: 0.3807 - val_accuracy: 1.0000 - val_loss: 0.3636\n",
      "Epoch 130/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - accuracy: 0.9951 - loss: 0.3577 - val_accuracy: 1.0000 - val_loss: 0.3396\n",
      "Epoch 131/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 201ms/step - accuracy: 0.9951 - loss: 0.3484 - val_accuracy: 1.0000 - val_loss: 0.3479\n",
      "Epoch 132/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 0.3496 - val_accuracy: 1.0000 - val_loss: 0.3447\n",
      "Epoch 133/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - accuracy: 1.0000 - loss: 0.3408 - val_accuracy: 0.9600 - val_loss: 0.3907\n",
      "Epoch 134/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step - accuracy: 0.9966 - loss: 0.3090 - val_accuracy: 0.9200 - val_loss: 0.5237\n",
      "Epoch 135/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 180ms/step - accuracy: 0.9758 - loss: 0.3973 - val_accuracy: 1.0000 - val_loss: 0.4674\n",
      "Epoch 136/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 196ms/step - accuracy: 0.9935 - loss: 0.4933 - val_accuracy: 0.9600 - val_loss: 0.5563\n",
      "Epoch 137/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 204ms/step - accuracy: 0.9929 - loss: 0.5452 - val_accuracy: 1.0000 - val_loss: 0.5327\n",
      "Epoch 138/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step - accuracy: 0.9815 - loss: 0.5490 - val_accuracy: 1.0000 - val_loss: 0.5146\n",
      "Epoch 139/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 207ms/step - accuracy: 0.9971 - loss: 0.5117 - val_accuracy: 1.0000 - val_loss: 0.4633\n",
      "Epoch 140/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 0.4571 - val_accuracy: 1.0000 - val_loss: 0.4158\n",
      "Epoch 141/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 200ms/step - accuracy: 0.9989 - loss: 0.3967 - val_accuracy: 1.0000 - val_loss: 0.3535\n",
      "Epoch 142/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 198ms/step - accuracy: 0.9940 - loss: 0.3561 - val_accuracy: 1.0000 - val_loss: 0.3253\n",
      "Epoch 143/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 200ms/step - accuracy: 0.9833 - loss: 0.3577 - val_accuracy: 0.9600 - val_loss: 0.3885\n",
      "Epoch 144/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 0.9760 - loss: 0.3988 - val_accuracy: 0.8800 - val_loss: 0.6128\n",
      "Epoch 145/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 182ms/step - accuracy: 0.9964 - loss: 0.3888 - val_accuracy: 0.9200 - val_loss: 0.6655\n",
      "Epoch 146/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 190ms/step - accuracy: 0.9951 - loss: 0.3806 - val_accuracy: 0.9600 - val_loss: 0.4770\n",
      "Epoch 147/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step - accuracy: 0.9951 - loss: 0.3762 - val_accuracy: 0.9200 - val_loss: 0.5782\n",
      "Epoch 148/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 190ms/step - accuracy: 0.9807 - loss: 0.3975 - val_accuracy: 0.9200 - val_loss: 0.6541\n",
      "Epoch 149/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step - accuracy: 1.0000 - loss: 0.4181 - val_accuracy: 0.8800 - val_loss: 0.7743\n",
      "Epoch 150/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 182ms/step - accuracy: 1.0000 - loss: 0.4085 - val_accuracy: 0.8800 - val_loss: 0.8379\n",
      "Epoch 151/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 180ms/step - accuracy: 1.0000 - loss: 0.3640 - val_accuracy: 0.8800 - val_loss: 0.7264\n",
      "Epoch 152/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 1.0000 - loss: 0.3086 - val_accuracy: 0.8800 - val_loss: 0.5404\n",
      "Epoch 153/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - accuracy: 1.0000 - loss: 0.2507 - val_accuracy: 0.9600 - val_loss: 0.3635\n",
      "Epoch 154/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 0.2046 - val_accuracy: 0.9600 - val_loss: 0.2638\n",
      "Epoch 155/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 209ms/step - accuracy: 1.0000 - loss: 0.1704 - val_accuracy: 0.9600 - val_loss: 0.2288\n",
      "Epoch 156/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 198ms/step - accuracy: 1.0000 - loss: 0.1460 - val_accuracy: 0.9600 - val_loss: 0.2004\n",
      "Epoch 157/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 196ms/step - accuracy: 0.9835 - loss: 0.2138 - val_accuracy: 0.9600 - val_loss: 0.4472\n",
      "Epoch 158/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 186ms/step - accuracy: 0.9926 - loss: 0.4195 - val_accuracy: 0.9200 - val_loss: 0.7681\n",
      "Epoch 159/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 193ms/step - accuracy: 0.9865 - loss: 0.5381 - val_accuracy: 0.8400 - val_loss: 1.4294\n",
      "Epoch 160/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 194ms/step - accuracy: 0.9891 - loss: 0.5586 - val_accuracy: 0.8400 - val_loss: 1.5849\n",
      "Epoch 161/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 0.5349 - val_accuracy: 0.8400 - val_loss: 1.5207\n",
      "Epoch 162/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 190ms/step - accuracy: 1.0000 - loss: 0.5036 - val_accuracy: 0.8800 - val_loss: 1.0103\n",
      "Epoch 163/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 197ms/step - accuracy: 1.0000 - loss: 0.4331 - val_accuracy: 0.9200 - val_loss: 0.6410\n",
      "Epoch 164/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 190ms/step - accuracy: 1.0000 - loss: 0.3701 - val_accuracy: 0.9600 - val_loss: 0.4662\n",
      "Epoch 165/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 0.3141 - val_accuracy: 0.9600 - val_loss: 0.3453\n",
      "Epoch 166/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 194ms/step - accuracy: 0.9974 - loss: 0.2612 - val_accuracy: 0.9200 - val_loss: 0.4112\n",
      "Epoch 167/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 0.2423 - val_accuracy: 0.8800 - val_loss: 0.5115\n",
      "Epoch 168/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 0.9903 - loss: 0.2460 - val_accuracy: 0.9600 - val_loss: 0.3746\n",
      "Epoch 169/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - accuracy: 0.9940 - loss: 0.2754 - val_accuracy: 1.0000 - val_loss: 0.3007\n",
      "Epoch 170/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 176ms/step - accuracy: 0.9906 - loss: 0.3732 - val_accuracy: 0.9200 - val_loss: 0.6120\n",
      "Epoch 171/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - accuracy: 1.0000 - loss: 0.5306 - val_accuracy: 0.9200 - val_loss: 0.7690\n",
      "Epoch 172/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 186ms/step - accuracy: 1.0000 - loss: 0.5640 - val_accuracy: 0.9200 - val_loss: 0.7624\n",
      "Epoch 173/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - accuracy: 0.9974 - loss: 0.5303 - val_accuracy: 0.9200 - val_loss: 0.6219\n",
      "Epoch 174/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 205ms/step - accuracy: 0.9977 - loss: 0.4845 - val_accuracy: 0.9200 - val_loss: 0.5882\n",
      "Epoch 175/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - accuracy: 1.0000 - loss: 0.4467 - val_accuracy: 0.9200 - val_loss: 0.6104\n",
      "Epoch 176/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - accuracy: 1.0000 - loss: 0.4229 - val_accuracy: 0.9200 - val_loss: 0.5031\n",
      "Epoch 177/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step - accuracy: 0.9966 - loss: 0.3753 - val_accuracy: 0.9600 - val_loss: 0.4119\n",
      "Epoch 178/300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 152\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m#X_train, X_test, y_train, y_test = train_test_split(combined_features, y_flattened, train_size=0.7, random_state=42, stratify=y)\u001b[39;00m\n\u001b[0;32m    151\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 152\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32mc:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import stft\n",
    "action_dict = {0:'left_hand',1:'right_hand',2:'foot',3:'tongue'}\n",
    "\n",
    "\n",
    "# Create epochs for all events\n",
    "all_epochs = mne.Epochs(raw, events[0], event_id=event_ids,  # No specific event_id filtering\n",
    "                        tmin=2, tmax=6, baseline=None, preload=True)\n",
    "all_epochs.pick_types(meg=False, eeg=True)\n",
    "\n",
    "X_all = all_epochs.get_data()\n",
    "event_ids_all = all_epochs.events[:, -1]\n",
    "print(X_all.shape,event_ids_all.shape)\n",
    "# sf = 250\n",
    "# for trial in range(1):\n",
    "#     for i in range(1):\n",
    "#         # Compute the STFT\n",
    "\n",
    "#         frequencies, times, Zxx = stft(X_all[trial,i,:], fs=sf, window='hann', nperseg=64, noverlap=0.5*64)\n",
    "\n",
    "#         # Plot the spectrogram\n",
    "#         plt.pcolormesh(times, frequencies, np.abs(Zxx), shading='gouraud')\n",
    "#         plt.title(f'STFT Spectrogram of EEG Signal: label={action_dict[event_ids_all[trial]-7]}, channel={i}')\n",
    "#         plt.ylabel('Frequency [Hz]')\n",
    "#         plt.xlabel('Time [sec]')\n",
    "#         plt.colorbar(label='Intensity')\n",
    "        \n",
    "#         plt.show()\n",
    "\n",
    "'''# Loop over each event ID for OvR CSP\n",
    "for event_id in event_ids:\n",
    "    # Generate binary labels: current class (1) vs rest (0)\n",
    "    y = (event_ids_all == event_id).astype(int)\n",
    "\n",
    "    # Check if both classes are present\n",
    "    if np.unique(y).size < 2:\n",
    "        print(f\"Skipping event_id {event_id} as it does not have two classes for CSP.\")\n",
    "        continue\n",
    "\n",
    "    print('y is:', y)  # Check the binary labels\n",
    "\n",
    "    # Apply CSP for the current binary classification\n",
    "    csp = CSP(n_components=4, norm_trace=False)\n",
    "    csp.fit(X_all, y)\n",
    "    csp_filters[event_id] = csp\n",
    "    X_csp = csp.transform(X_all)\n",
    "\n",
    "    # Append the features\n",
    "    combined_features.append(X_csp)\n",
    "\n",
    "combined_features = np.concatenate(combined_features, axis=1) if combined_features else np.array([])'''\n",
    "ncomp = 4\n",
    "csp_transformed_data = {}\n",
    "for event_id in event_ids:\n",
    "    y = (event_ids_all == event_id).astype(int)\n",
    "    if np.unique(y).size < 2:\n",
    "        print(f\"Skipping event_id {event_id}.\")\n",
    "        continue\n",
    "\n",
    "    csp = CSP(n_components=ncomp, norm_trace=False, transform_into='csp_space')\n",
    "    csp.fit(X_all, y)\n",
    "    csp_transformed_data[event_id] = csp.transform(X_all)\n",
    "\n",
    "print('CSP FILTERS DICT:',csp_transformed_data)\n",
    "# Combine CSP features for each trial based on its label\n",
    "n_trials = len(X_all)  # Number of trials\n",
    "n_components = ncomp       # Number of CSP components (assuming 3 for this example)\n",
    "n_time_points = csp_transformed_data[7].shape[2]   # Number of time points in the transformed CSP data\n",
    "\n",
    "# Initialize the combined_features array to hold CSP features for all trials\n",
    "combined_features = np.zeros((n_trials, n_components, n_time_points))\n",
    "\n",
    "# Loop through each trial and assign the CSP-transformed data\n",
    "for i, label in enumerate(event_ids_all):\n",
    "    # Fetch the CSP features for the current trial and class label\n",
    "    # Adjust the indexing based on how your labels and csp_transformed_data are structured\n",
    "    csp_features_for_label = csp_transformed_data.get(label, None)\n",
    "\n",
    "    # Check if the label exists in the dictionary and if the index is within bounds\n",
    "    if csp_features_for_label is not None and i < len(csp_features_for_label):\n",
    "        combined_features[i, :, :] = csp_features_for_label[i]\n",
    "\n",
    "print(combined_features.shape)\n",
    "\n",
    "print(combined_features.shape)\n",
    "y = np.zeros((X_all.shape[0], len(event_ids)))  \n",
    "\n",
    "for i, event_id in enumerate(event_ids):\n",
    "    binary_labels = (event_ids_all == event_id).astype(int)\n",
    "    y[:, i] = binary_labels  \n",
    "print(y)\n",
    "\n",
    "y_flattened = np.argmax(y, axis=1)\n",
    "print(y_flattened)\n",
    "print(y_flattened.tolist().count(0),y_flattened.tolist().count(1),y_flattened.tolist().count(2),y_flattened.tolist().count(3))\n",
    "# clf = Pipeline([('scaler',StandardScaler()),('SVC', SVC())])\n",
    "print('features shape: ',combined_features.shape,y_flattened.shape)\n",
    "# scores = cross_val_score(clf, combined_features, y_flattened, cv=10, scoring='accuracy')\n",
    "# print(\"Multiclass classification accuracy: %f\" % scores.mean())\n",
    "\n",
    "ftrs = featuresarray_load(combined_features)\n",
    "\n",
    "print('features shape: ',ftrs.shape,y_flattened.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(ftrs, y_flattened, train_size=0.85, random_state=42, stratify=y_flattened)\n",
    "\n",
    "\n",
    "from keras.layers import PReLU, Conv1D, Dropout, SpatialDropout1D, MaxPooling1D, GlobalMaxPooling1D, Layer, AveragePooling1D, LSTM, Reshape, BatchNormalization\n",
    "from keras.regularizers import l1_l2\n",
    "# model = Sequential([\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dense(128, activation='tanh'),\n",
    "#     Dropout(0.2),\n",
    "#     Dense(len(event_ids), activation='softmax')  \n",
    "# ])\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "GLOBAL_SHAPE_LENGTH = ftrs.shape[2]\n",
    "model = Sequential([\n",
    "        Reshape((GLOBAL_SHAPE_LENGTH,ncomp)),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        Conv1D(64, kernel_size=7),\n",
    "        PReLU(),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        SpatialDropout1D(0.1),\n",
    "\n",
    "        Conv1D(128, kernel_size=5),\n",
    "        BatchNormalization(),\n",
    "        PReLU(),\n",
    "        AveragePooling1D(pool_size=2),\n",
    "        SpatialDropout1D(0.1),\n",
    "\n",
    "        LSTM(128, activation='tanh', recurrent_regularizer=l1_l2(l1=0.01, l2=0.01),return_sequences=True),\n",
    "        BatchNormalization(),\n",
    "        GlobalMaxPooling1D(),\n",
    "        BatchNormalization(),\n",
    "        Dense(units=128, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.1),\n",
    "        Dense(units=64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.1),\n",
    "        Dense(units=4, activation='softmax')\n",
    "    ])\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(combined_features, y_flattened, train_size=0.7, random_state=42, stratify=y)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=300, validation_split=0.1, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.3712\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_test,y_test)[1]*100.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
    "\n",
    "for _ in range(25):\n",
    "    sample_index_train = random.randint(0, len(X_train) - 1)\n",
    "    train_sample = X_train[sample_index_train]\n",
    "    train_label = y_train[sample_index_train]\n",
    "\n",
    "    match_indices = np.where(y_test == train_label)[0]\n",
    "    sample_index_test = random.choice(match_indices)\n",
    "    test_sample = X_test[sample_index_test]\n",
    "\n",
    "    time_axis = np.arange(train_sample.shape[1])  # Time points on the x-axis\n",
    "\n",
    "    plt.figure(figsize=(24, 6))\n",
    "\n",
    "    # Plot train sample\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for channel in range(train_sample.shape[0]):\n",
    "        plt.plot(time_axis, train_sample[channel, :], label=f'Channel {channel+1}')\n",
    "    plt.title(f\"Train Sample {sample_index_train}, Label {train_label}\")\n",
    "    plt.xlabel(\"Time Point\")\n",
    "    plt.ylabel(\"Signal Amplitude\")\n",
    "    plt.ylim((-1, 1))\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot test sample\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for channel in range(test_sample.shape[0]):\n",
    "        plt.plot(time_axis, test_sample[channel, :], label=f'Channel {channel+1}')\n",
    "    plt.title(f\"Test Sample {sample_index_test}, Label {y_test[sample_index_test]}\")\n",
    "    plt.xlabel(\"Time Point\")\n",
    "    plt.ylabel(\"Signal Amplitude\")\n",
    "    plt.ylim((-1, 1))\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "lst = y_train.tolist()\n",
    "print(lst.count(0),lst.count(1),lst.count(2),lst.count(3),GLOBAL_SHAPE_LENGTH)\n",
    "lst = y_test.tolist()\n",
    "print(lst.count(0),lst.count(1),lst.count(2),lst.count(3),GLOBAL_SHAPE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Define a custom dataset class for handling the EMG data\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)  # Convert data to torch tensors\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)  # Convert labels to torch tensors\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Return a tuple of (data, label) for each index\n",
    "        return self.data[index], self.labels[index]\n",
    "\n",
    "# Assuming X_train and y_train are numpy arrays\n",
    "# Create a custom dataset using the EMGDataset class\n",
    "train_dataset = EEGDataset(X_train, y_train)\n",
    "test_dataset = EEGDataset(X_test, y_test)\n",
    "\n",
    "# Create DataLoader for the training and test sets\n",
    "batch_size = 32  # Set an appropriate batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snntorch import surrogate\n",
    "from torch import nn\n",
    "import snntorch as snn\n",
    "\n",
    "# Define the necessary parameters (ensure these match your model's requirements)\n",
    "num_inputs = 4 * 510  # Flattened input size: 4 channels x 137 time steps\n",
    "num_hidden = 1000     # Number of hidden units in the first fully connected layer\n",
    "num_outputs = 4       # Number of output classes (assuming 3 classes in the target labels)\n",
    "beta = 0.95            # Decay constant for the LIF neuron\n",
    "num_steps = 510       # Number of time steps (should match the temporal dimension of your data)\n",
    "\n",
    "# Define Network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)  # Input: 548 (4*137), Output: 1000 hidden units\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)  # Output: 3 classes\n",
    "        self.lif2 = snn.Leaky(beta=beta)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the input outside the loop for all samples in the batch\n",
    "        # Convert (batch_size, num_channels, num_timesteps) -> (batch_size, num_channels * num_timesteps)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input to shape: (batch_size, 548)\n",
    "\n",
    "        # Initialize hidden states at t=0\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        \n",
    "        # Record the final layer outputs\n",
    "        spk2_rec = []\n",
    "        mem2_rec = []\n",
    "\n",
    "        # time-loop: Iterate through each time step\n",
    "        for step in range(num_steps):\n",
    "            # Pass through the first fully connected layer\n",
    "            x = x.flatten(1)\n",
    "            cur1 = self.fc1(x)  # Use the flattened input\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "\n",
    "            # Pass through the second fully connected layer\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "          \n",
    "            # Store in list\n",
    "            spk2_rec.append(spk2)\n",
    "            mem2_rec.append(mem2)\n",
    "\n",
    "        # Stack the outputs over time to return the final tensor\n",
    "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)  # Shape: (time_steps, batch_size, num_outputs)\n",
    "        \n",
    "# Load the network onto CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = Net().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "\n",
    "num_epochs = 15 # 60000 / 128 = 468 \n",
    "counter = 0\n",
    "\n",
    "# Outer training loop\n",
    "for epoch in range(num_epochs):\n",
    "    train_batch = iter(train_loader)\n",
    "\n",
    "    # Minibatch training loop\n",
    "    for data, targets in train_batch:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        net.train()\n",
    "        spk_rec, _ = net(data)\n",
    "\n",
    "        # initialize the loss & sum over time\n",
    "        loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
    "        loss_val = loss(spk_rec.sum(0), targets) # batch x num_out\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print train/test loss/accuracy\n",
    "        if counter % 10 == 0:\n",
    "            print(f\"Iteration: {counter} \\t Train Loss: {loss_val.item()}\")\n",
    "        counter += 1\n",
    "\n",
    "        if counter == 100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_accuracy(model, dataloader):\n",
    "  with torch.no_grad():\n",
    "    model.eval()\n",
    "    running_length = 0\n",
    "    running_accuracy = 0\n",
    "\n",
    "    for data, targets in iter(dataloader):\n",
    "      data = data.to(device)\n",
    "      targets = targets.to(device)\n",
    "\n",
    "      # forward-pass\n",
    "      spk_rec, _ = model(data)\n",
    "      spike_count = spk_rec.sum(0) # batch x num_outputs\n",
    "      _, max_spike = spike_count.max(1)\n",
    "\n",
    "      # correct classes for one batch\n",
    "      num_correct = (max_spike == targets).sum()\n",
    "\n",
    "      # total accuracy\n",
    "      running_length += len(targets)\n",
    "      running_accuracy += num_correct\n",
    "    \n",
    "    accuracy = (running_accuracy / running_length)\n",
    "\n",
    "    return accuracy.item()\n",
    "print(f\"Test set accuracy: {measure_accuracy(net, test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HBTySQPRIgiE",
    "outputId": "3ea3d41e-cc63-4c22-eea1-3f8875725d81"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class Plasticity(gym.Env):\n",
    "  #dataset=(X_train, y_train)\n",
    "    def __init__(self, images_per_episode=1, dataset=(X_train, y_train), random=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(4)\n",
    "        self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf,\n",
    "                                                shape=(GLOBAL_SHAPE_LENGTH,ncomp),\n",
    "                                                dtype=np.float32)\n",
    "        self.images_per_episode = images_per_episode\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.x, self.y = dataset\n",
    "        self.random = random\n",
    "        self.dataset_idx = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        reward = self.calculate_reward(action)\n",
    "\n",
    "        obs = self._next_obs()\n",
    "\n",
    "        self.step_count += 1\n",
    "        if self.step_count >= self.images_per_episode:\n",
    "            done = True\n",
    "\n",
    "        return obs, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.step_count = 0\n",
    "\n",
    "        obs = self._next_obs()\n",
    "        return obs\n",
    "\n",
    "    def _next_obs(self):\n",
    "        if self.random:\n",
    "            next_obs_idx = random.randint(0, len(self.x) - 1)\n",
    "            self.expected_action = int(self.y[next_obs_idx])\n",
    "            obs = self.x[next_obs_idx]\n",
    "        else:\n",
    "            obs = self.x[self.dataset_idx]\n",
    "            self.expected_action = int(self.y[self.dataset_idx])\n",
    "\n",
    "            self.dataset_idx += 1\n",
    "            if self.dataset_idx >= len(self.x):\n",
    "                raise StopIteration()\n",
    "\n",
    "        return obs\n",
    "\n",
    "    def calculate_reward(self, action):\n",
    "      if action == self.expected_action:\n",
    "          reward = 1\n",
    "      else:\n",
    "          reward = 0\n",
    "\n",
    "      return reward\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lJ-Ph6WjIpSz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten,Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "tf.compat.v1.experimental.output_all_intermediates(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NN7Tbe6FIrES",
    "outputId": "9ecbeb57-1b86-421a-f19a-5e99556593c4"
   },
   "outputs": [],
   "source": [
    "env = Plasticity()\n",
    "states = env.observation_space.shape\n",
    "actions = env.action_space.n\n",
    "print(env.action_space)\n",
    "print(states,actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zYwn-zUpIsXc"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, Dropout, AveragePooling1D, SpatialDropout1D, MaxPooling1D, BatchNormalization, LSTM, Flatten, Dense, PReLU, Reshape\n",
    "from keras.models import Sequential\n",
    "from keras.backend import clear_session\n",
    "from keras.regularizers import l1_l2\n",
    "\n",
    "def build_model(states, actions):\n",
    "    model = Sequential([\n",
    "        Reshape((GLOBAL_SHAPE_LENGTH,ncomp,),input_shape=(1,ncomp,GLOBAL_SHAPE_LENGTH)),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        Conv1D(64, kernel_size=7),\n",
    "        PReLU(),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        SpatialDropout1D(0.1),\n",
    "\n",
    "        Conv1D(128, kernel_size=5),\n",
    "        BatchNormalization(),\n",
    "        PReLU(),\n",
    "        AveragePooling1D(pool_size=2),\n",
    "        SpatialDropout1D(0.1),\n",
    "\n",
    "        LSTM(128, activation='tanh', recurrent_regularizer=l1_l2(l1=0.01, l2=0.01),return_sequences=True),\n",
    "        BatchNormalization(),\n",
    "        GlobalMaxPooling1D(),\n",
    "        BatchNormalization(),\n",
    "        Dense(units=128, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.1),\n",
    "        Dense(units=64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.1),\n",
    "        Dense(units=actions, activation='linear')\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cGGX6HXlIuua",
    "outputId": "454633ac-3f15-4cc8-8458-0d7960f7aa10"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#!pip install keras-rl2\n",
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy, EpsGreedyQPolicy, LinearAnnealedPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from keras import __version__\n",
    "import tensorflow as tf\n",
    "\n",
    "# To reset all information and start fresh, clear the current Keras session:\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "#with strategy.scope():\n",
    "model = build_model(states, actions)\n",
    "\n",
    "model.build(input_shape=(1,*states))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GBv8l1MKIwD6"
   },
   "outputs": [],
   "source": [
    "def build_agent(model, actions):\n",
    "    policy = EpsGreedyQPolicy(eps=1.0)\n",
    "    memory = SequentialMemory(limit=30000, window_length=1)\n",
    "    dqn = DQNAgent(model=model, memory=memory, policy=policy,\n",
    "                  nb_actions=actions, nb_steps_warmup=100, target_model_update=1e-4)\n",
    "    return dqn, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73cjkIeuIxpb",
    "outputId": "da470881-6501-4ca9-ebe6-4613e7943842"
   },
   "outputs": [],
   "source": [
    "dqn, policy = build_agent(model, actions)\n",
    "dqn.compile(tf.keras.optimizers.legacy.Adam(learning_rate=0.0005,decay=1e-3), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ck7ckYMYIy3y",
    "outputId": "3afff6b9-b732-449f-8847-3d762b332109"
   },
   "outputs": [],
   "source": [
    "from rl.callbacks import Callback\n",
    "\n",
    "#print(dqn.policy.eps)\n",
    "class LossHistory(Callback):\n",
    "    def __init__(self):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_step_end(self, step, logs={}):\n",
    "        self.losses.append(logs['metrics'][0])\n",
    "\n",
    "class LossHistory2(Callback):\n",
    "    def __init__(self):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_step_end(self, step, logs={}):\n",
    "        self.losses.append(logs['metrics'][1])\n",
    "\n",
    "class RewardHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.rewards = []\n",
    "\n",
    "    def on_episode_end(self, episode, logs={}):\n",
    "        self.rewards.append(logs['episode_reward'])\n",
    "\n",
    "class ExponentialDecayEpsilonCallback(Callback):\n",
    "    def __init__(self, initial_epsilon, min_epsilon, decay_rate, decay_steps):\n",
    "        self.epsilon = initial_epsilon\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.decay_rate = decay_rate\n",
    "        self.decay_steps = decay_steps\n",
    "        self.step_count = 0\n",
    "\n",
    "    def on_step_end(self, step, logs={}):\n",
    "        self.step_count += 1\n",
    "        # if(self.epsilon <= 1e-10):\n",
    "        #     self.epsilon=0.5\n",
    "        self.epsilon = self.min_epsilon + (self.epsilon - self.min_epsilon) * np.exp(-self.step_count / self.decay_steps)\n",
    "        self.model.policy.eps = max(self.epsilon, self.min_epsilon)\n",
    "        \n",
    "        if(self.step_count % 100 == 0): print(f\" Epsilon: {self.epsilon}\")\n",
    "\n",
    "\n",
    "initial_epsilon = 1.0  \n",
    "min_epsilon = 0.0  \n",
    "decay_rate = 0.0001    \n",
    "decay_steps = 100000   \n",
    "\n",
    "epsilon_decay_cb = ExponentialDecayEpsilonCallback(initial_epsilon, min_epsilon, decay_rate, decay_steps)\n",
    "\n",
    "\n",
    "loss_history = LossHistory()\n",
    "loss_history2 = LossHistory2()\n",
    "reward_history = RewardHistory()\n",
    "\n",
    "\n",
    "#dqn.load_weights(prefix+'bciiv2a_dqn_weights.hdf5')\n",
    "dqn.fit(env, nb_steps=2500, callbacks=[loss_history,loss_history2,reward_history,epsilon_decay_cb], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.policy.eps = 0\n",
    "dqn.fit(env, nb_steps=250, callbacks=[loss_history,loss_history2,reward_history], verbose=1)\n",
    "dqn.fit(env, nb_steps=250, callbacks=[loss_history,loss_history2,reward_history], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R_-Qcn1XvAqM",
    "outputId": "d7a5723a-9cb3-4dea-8e58-11c1cbec7790"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def dqn_eval(dqn_agent,d):\n",
    "    attempts, correct = 0, 0\n",
    "    labels = d[1]\n",
    "    eenv = Plasticity(dataset=d, random=False)\n",
    "    thing = 1\n",
    "    y_predFull = []\n",
    "    y_trueest = []\n",
    "    total_reward = 0\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "\n",
    "        while True:\n",
    "\n",
    "            if thing == 1:\n",
    "                obs = eenv.reset()\n",
    "                thing = 0\n",
    "            done = False\n",
    "            while not done:\n",
    "\n",
    "                obs_reshaped = np.reshape(obs, (1,) + obs.shape)\n",
    "\n",
    "                q_values = dqn_agent.compute_q_values(obs_reshaped)\n",
    "                #print(q_values)\n",
    "\n",
    "                action = np.argmax(q_values)\n",
    "\n",
    "                #print('action: ', action, \" - \", labels[attempts])\n",
    "                y_predFull.append(action)\n",
    "                y_trueest.append(labels[attempts])\n",
    "\n",
    "                obs, rew, done, _ = eenv.step(action)\n",
    "                total_reward += rew\n",
    "                if done:\n",
    "                    attempts += 1\n",
    "\n",
    "    except StopIteration:\n",
    "        print()\n",
    "        print('Validation done...','total reward=',total_reward)\n",
    "\n",
    "        y_predFull = np.array(y_predFull)\n",
    "        y_trueest = np.array(y_trueest)\n",
    "\n",
    "        cm = confusion_matrix(y_trueest, y_predFull)\n",
    "        print(y_predFull)\n",
    "        print(y_trueest)\n",
    "\n",
    "        print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "        report = classification_report(y_trueest, y_predFull,digits=4)\n",
    "        print(\"Classification Report:\\n\", report)\n",
    "\n",
    "        report = classification_report(y_trueest, y_predFull,output_dict=True)\n",
    "\n",
    "        correct = sum(y_predFull == y_trueest)\n",
    "        attempts = len(y_trueest)\n",
    "        accuracy = (float(correct) / attempts)\n",
    "        print('Validation done...')\n",
    "        print('Accuracy: {:.2f}%'.format(accuracy*100))\n",
    "\n",
    "        F1 = report['macro avg']['f1-score']\n",
    "        precision = report['macro avg']['precision']\n",
    "        recall = report['macro avg']['recall']\n",
    "\n",
    "        print(\"F1 Score: {:.2f}%\".format(F1*100))\n",
    "        print(\"Precision: {:.2f}%\".format(precision*100))\n",
    "        print(\"Recall: {:.2f}%\".format(recall*100))\n",
    "\n",
    "    y_predFull = []\n",
    "    y_trueest = []\n",
    "    return accuracy, F1, precision, recall\n",
    "\n",
    "dqn_eval(dqn,d=(X_train,y_train))\n",
    "print('***************************************************************************************')\n",
    "dqn_eval(dqn,d=(X_test,y_test))\n",
    "print('***************************************************************************************')\n",
    "import math\n",
    "def dqn_eval2(thing,dataset):\n",
    "\n",
    "    n_splits = 10\n",
    "\n",
    "    mean_rewards_per_fold = []\n",
    "    acc_per_fold = []\n",
    "    f1_mean, p_mean, r_mean = [], [], []\n",
    "\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    # if flag:\n",
    "    #   train = X_train\n",
    "    #   test = y_train\n",
    "    # else:\n",
    "    #   train = X_test\n",
    "    #   test = y_test\n",
    "    train, test = dataset\n",
    "   \n",
    "    for train_index, test_index in skf.split(train,test):\n",
    "        xtr, xte = train[train_index],train[test_index]\n",
    "        ytr, yte = test[train_index], test[test_index]\n",
    "\n",
    "        test_env = Plasticity(dataset = (xte, yte),random=True)\n",
    "        \n",
    "        scores = dqn.test(test_env, nb_episodes=10, visualize=False, verbose=0)\n",
    "        acc, f1, p, r = dqn_eval(dqn,d=(xte, yte))\n",
    "        \n",
    "        mean_reward = np.mean(scores.history['episode_reward'])\n",
    "        mean_rewards_per_fold.append(mean_reward)\n",
    "        acc_per_fold.append(acc)\n",
    "        f1_mean.append(f1)\n",
    "        r_mean.append(r)\n",
    "        p_mean.append(p)\n",
    "        \n",
    "\n",
    "    overall_mean_reward = np.mean(mean_rewards_per_fold)\n",
    "\n",
    "    f1_avg, p_avg, r_avg = np.mean(f1_mean), np.mean(p_mean), np.mean(r_mean)\n",
    "    print(f\"Overall Mean Reward across all folds: {overall_mean_reward}\")\n",
    "    acc_avg = np.mean(acc_per_fold)\n",
    "    print(f\"Overall Mean Accuracy across all folds: {acc_avg * 100} %\")\n",
    "    print(f\"Overall Mean F1 across all folds: {f1_avg * 100} %\")\n",
    "    print(f\"Overall Mean Precision across all folds: {p_avg * 100} %\")\n",
    "    print(f\"Overall Mean Recall across all folds: {r_avg * 100} %\")\n",
    "\n",
    "def dqn_eval3(dqn_agent, dataset):\n",
    "\n",
    "    n_splits = 10\n",
    "\n",
    "    mean_rewards_per_fold = []\n",
    "    acc_per_fold = []\n",
    "    f1_mean, p_mean, r_mean = [], [], []\n",
    "    \n",
    "    train,test=dataset\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    for train_index, test_index in skf.split(train,test):\n",
    "        xtr, xte = train[train_index],train[test_index]\n",
    "        ytr, yte = test[train_index], test[test_index]\n",
    "\n",
    "        test_env = Plasticity(dataset = (xte, yte),random=True)\n",
    "        \n",
    "        scores = dqn.test(test_env, nb_episodes=10, visualize=False, verbose=0)\n",
    "        acc, f1, p, r = dqn_eval(dqn,d=(xte, yte))\n",
    "        \n",
    "        mean_reward = np.mean(scores.history['episode_reward'])\n",
    "        mean_rewards_per_fold.append(mean_reward)\n",
    "        acc_per_fold.append(acc)\n",
    "        f1_mean.append(f1)\n",
    "        r_mean.append(r)\n",
    "        p_mean.append(p)\n",
    "        \n",
    "\n",
    "    overall_mean_reward = np.mean(mean_rewards_per_fold)\n",
    "\n",
    "    f1_avg, p_avg, r_avg = np.mean(f1_mean), np.mean(p_mean), np.mean(r_mean)\n",
    "    print(f\"Overall Mean Reward across all folds: {overall_mean_reward}\")\n",
    "    acc_avg = np.mean(acc_per_fold)\n",
    "    print(f\"Overall Mean Accuracy across all folds: {acc_avg * 100} %\")\n",
    "    print(f\"Overall Mean F1 across all folds: {f1_avg * 100} %\")\n",
    "    print(f\"Overall Mean Precision across all folds: {p_avg * 100} %\")\n",
    "    print(f\"Overall Mean Recall across all folds: {r_avg * 100} %\")\n",
    "features_array, label_array = np.concatenate((X_train,X_test)),np.concatenate((y_train,y_test))\n",
    "dqn_eval2(thing=True, dataset=(features_array,label_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Confusion matrix data\n",
    "conf_matrix = np.array([[ 9,  1,  0,  0],\n",
    " [ 0, 11,  0 , 0],\n",
    " [ 0,  0 ,11,  0],\n",
    " [ 0,  0 , 0 ,11]])\n",
    "\n",
    "# Normalize the confusion matrix row-wise for percentages\n",
    "row_sums = conf_matrix.sum(axis=1)\n",
    "conf_matrix_percent = conf_matrix / row_sums[:, np.newaxis] * 100\n",
    "\n",
    "# Create an annotation matrix for displaying counts and percentages\n",
    "annotations = np.empty_like(conf_matrix, dtype=object)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        annotations[i, j] = f\"{conf_matrix[i, j]}\\n{conf_matrix_percent[i, j]:.2f}%\"\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix_percent, annot=annotations, fmt=\"\", cmap=\"Blues\", cbar=True,\n",
    "            xticklabels=[0, 1, 2, 3], yticklabels=[0, 1, 2, 3])\n",
    "plt.ylabel('Actual Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Confusion Matrix with Samples and Percentages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Z5i1pJFud0Hk",
    "outputId": "2e2f65b0-85e0-4366-fce7-866d3239f3c4"
   },
   "outputs": [],
   "source": [
    "device_name = '/device:GPU:0'\n",
    "#dqn_eval2(thing=True,flag=False)\n",
    "# print(np.mean(scores.history['episode_reward'])*100,'%')\n",
    "# plt.plot(scores.history['episode_reward'])\n",
    "# plt.title('Testing Rewards per Episode')\n",
    "# plt.xlabel('Episode')\n",
    "# plt.ylabel('Cumulative Reward')\n",
    "# plt.show()\n",
    "# print(np.mean(scores.history['episode_reward'])*100,'%')\n",
    "dqn.policy.eps = 0\n",
    "# train_new = np.load(file='/content/drive/MyDrive/a/bciiv2a_test_features_A02E.gdf.npy')\n",
    "# train_new_labels = train_dict['A02T.gdf']['labels']\n",
    "\n",
    "#dqn_eval(dqn,d=(X_test[len(X_test)-25:],y_test[len(y_test)-25:]))\n",
    "dqn_eval(dqn,d=(X_test,y_test))\n",
    "\n",
    "dqn.policy.eps = 0\n",
    "scores = dqn.test(Plasticity(images_per_episode=1,random=True,dataset=(X_test,y_test)), nb_episodes=10, visualize=False, action_repetition=1, verbose=1)\n",
    "print(np.mean(scores.history['episode_reward'])*100.,'%')\n",
    "\n",
    "\n",
    "def moving_average(data, window_size):\n",
    "    return [np.mean(data[i:i+window_size]) for i in range(len(data) - window_size + 1)]\n",
    "losses = loss_history.losses\n",
    "losses2 = loss_history2.losses\n",
    "smoothed_losses = moving_average(losses, window_size=50)\n",
    "print(smoothed_losses)\n",
    "plt.plot(smoothed_losses)\n",
    "plt.title('Smoothed Training Loss per Step')\n",
    "plt.xlabel('Step')\n",
    "plt.xlim(left=0)\n",
    "plt.ylabel('Smoothed Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "smoothed_losses2 = moving_average(losses2, window_size=70)\n",
    "print(smoothed_losses2)\n",
    "plt.plot(smoothed_losses2)\n",
    "plt.title('Smoothed Training Loss per Step')\n",
    "plt.xlabel('Step')\n",
    "plt.xlim(left=0)\n",
    "plt.ylabel('Smoothed Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(moving_average(reward_history.rewards, window_size=70))\n",
    "# plt.title('Training Rewards per Episode')\n",
    "# plt.xlabel('Episode')\n",
    "# plt.ylabel('Cumulative Reward')\n",
    "# plt.show()\n",
    "\n",
    "print(\"___________________________________________________________________________________________________________________________\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TheVirtualEnv",
   "language": "python",
   "name": "thevirtualenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
